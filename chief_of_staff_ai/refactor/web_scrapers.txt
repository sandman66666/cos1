# File: chief_of_staff_ai/intelligence/web_scrapers.py
"""
Web Intelligence Workers for Contact Enrichment
==============================================
Parallel web scraping to enrich contact data with social/professional context
"""

import asyncio
import aiohttp
from typing import Dict, List, Optional
from dataclasses import dataclass
from playwright.async_api import async_playwright
import logging
from datetime import datetime
import re

logger = logging.getLogger(__name__)

@dataclass
class ContactEnrichmentResult:
    """Enriched contact information from web sources"""
    email: str
    linkedin_data: Optional[Dict] = None
    twitter_data: Optional[Dict] = None
    company_data: Optional[Dict] = None
    enrichment_timestamp: datetime = None
    confidence_score: float = 0.0

class WebIntelligenceWorker:
    """Base class for web intelligence workers"""
    
    def __init__(self):
        self.session = None
        self.browser = None
        
    async def setup(self):
        """Initialize browser and session"""
        self.session = aiohttp.ClientSession()
        playwright = await async_playwright().start()
        self.browser = await playwright.chromium.launch(headless=True)
        
    async def cleanup(self):
        """Clean up resources"""
        if self.session:
            await self.session.close()
        if self.browser:
            await self.browser.close()

class LinkedInWorker(WebIntelligenceWorker):
    """Extract LinkedIn profile data for contacts"""
    
    async def enrich_contact(self, name: str, company: str = None) -> Optional[Dict]:
        """Search LinkedIn and extract profile data"""
        try:
            page = await self.browser.new_page()
            
            # Search LinkedIn (Note: In production, use LinkedIn API or respect robots.txt)
            search_query = f"{name} {company}" if company else name
            search_url = f"https://www.linkedin.com/search/results/people/?keywords={search_query}"
            
            await page.goto(search_url, wait_until='networkidle')
            
            # Extract first result (simplified - enhance with better selectors)
            profile_data = await page.evaluate('''() => {
                const firstResult = document.querySelector('.search-result__wrapper');
                if (!firstResult) return null;
                
                return {
                    name: firstResult.querySelector('.actor-name')?.innerText,
                    title: firstResult.querySelector('.subline-level-1')?.innerText,
                    company: firstResult.querySelector('.subline-level-2')?.innerText,
                    location: firstResult.querySelector('.subline-level-3')?.innerText,
                    profileUrl: firstResult.querySelector('a')?.href
                };
            }''')
            
            await page.close()
            
            if profile_data and profile_data.get('profileUrl'):
                # Get detailed profile data
                detailed_data = await self._get_profile_details(profile_data['profileUrl'])
                return {**profile_data, **detailed_data}
            
            return profile_data
            
        except Exception as e:
            logger.error(f"LinkedIn enrichment error for {name}: {str(e)}")
            return None
    
    async def _get_profile_details(self, profile_url: str) -> Dict:
        """Extract detailed profile information"""
        try:
            page = await self.browser.new_page()
            await page.goto(profile_url, wait_until='networkidle')
            
            details = await page.evaluate('''() => {
                return {
                    headline: document.querySelector('.top-card-layout__headline')?.innerText,
                    about: document.querySelector('.summary')?.innerText,
                    experience_count: document.querySelectorAll('.experience-item').length,
                    skills: Array.from(document.querySelectorAll('.skill-pill')).map(s => s.innerText),
                    recent_activity: document.querySelector('.recent-activity')?.innerText
                };
            }''')
            
            await page.close()
            return details
            
        except Exception as e:
            logger.error(f"LinkedIn profile details error: {str(e)}")
            return {}

class TwitterWorker(WebIntelligenceWorker):
    """Extract Twitter/X profile and recent tweets"""
    
    async def enrich_contact(self, name: str, email: str = None) -> Optional[Dict]:
        """Find Twitter handle and extract profile data"""
        try:
            # Search by name or email username
            username_guess = email.split('@')[0] if email else name.lower().replace(' ', '')
            
            # Try direct profile access first
            profile_url = f"https://twitter.com/{username_guess}"
            
            async with self.session.get(profile_url) as response:
                if response.status == 200:
                    # Extract profile data (simplified - use proper API in production)
                    return {
                        'handle': username_guess,
                        'profile_url': profile_url,
                        'twitter_verified': True
                    }
            
            # If direct access fails, search
            return await self._search_twitter(name)
            
        except Exception as e:
            logger.error(f"Twitter enrichment error for {name}: {str(e)}")
            return None
    
    async def _search_twitter(self, name: str) -> Optional[Dict]:
        """Search Twitter for a person"""
        # Implement Twitter search logic
        return None

class CompanyIntelligenceWorker(WebIntelligenceWorker):
    """Extract company information from web sources"""
    
    async def enrich_company(self, company_name: str, domain: str = None) -> Optional[Dict]:
        """Get company intelligence from multiple sources"""
        try:
            company_data = {}
            
            # Try company website first
            if domain:
                website_data = await self._analyze_company_website(domain)
                company_data.update(website_data)
            
            # Search for news and funding information
            news_data = await self._search_company_news(company_name)
            company_data.update(news_data)
            
            # Get company metrics if available
            metrics = await self._get_company_metrics(company_name)
            company_data.update(metrics)
            
            return company_data
            
        except Exception as e:
            logger.error(f"Company enrichment error for {company_name}: {str(e)}")
            return None
    
    async def _analyze_company_website(self, domain: str) -> Dict:
        """Extract information from company website"""
        try:
            url = f"https://{domain}" if not domain.startswith('http') else domain
            
            page = await self.browser.new_page()
            await page.goto(url, wait_until='networkidle')
            
            company_info = await page.evaluate('''() => {
                return {
                    title: document.title,
                    description: document.querySelector('meta[name="description"]')?.content,
                    about_text: document.querySelector('[class*="about"]')?.innerText?.substring(0, 500),
                    team_size_indicator: document.querySelectorAll('[class*="team"] img, [class*="team"] .member').length
                };
            }''')
            
            await page.close()
            return company_info
            
        except Exception as e:
            logger.error(f"Company website analysis error: {str(e)}")
            return {}
    
    async def _search_company_news(self, company_name: str) -> Dict:
        """Search for recent company news"""
        # Implement news search
        return {'has_recent_news': False}
    
    async def _get_company_metrics(self, company_name: str) -> Dict:
        """Get company metrics from public sources"""
        # Implement metrics gathering
        return {'estimated_size': 'unknown'}

class ContactEnrichmentOrchestrator:
    """Orchestrate parallel contact enrichment across multiple sources"""
    
    def __init__(self):
        self.linkedin_worker = LinkedInWorker()
        self.twitter_worker = TwitterWorker()
        self.company_worker = CompanyIntelligenceWorker()
        
    async def enrich_contacts_batch(self, contacts: List[Dict]) -> List[ContactEnrichmentResult]:
        """Enrich a batch of contacts in parallel"""
        # Setup workers
        await asyncio.gather(
            self.linkedin_worker.setup(),
            self.twitter_worker.setup(),
            self.company_worker.setup()
        )
        
        try:
            # Process contacts in parallel
            enrichment_tasks = []
            for contact in contacts:
                task = self._enrich_single_contact(contact)
                enrichment_tasks.append(task)
            
            results = await asyncio.gather(*enrichment_tasks, return_exceptions=True)
            
            # Filter out exceptions
            valid_results = []
            for result in results:
                if isinstance(result, ContactEnrichmentResult):
                    valid_results.append(result)
                else:
                    logger.error(f"Enrichment error: {result}")
            
            return valid_results
            
        finally:
            # Cleanup
            await asyncio.gather(
                self.linkedin_worker.cleanup(),
                self.twitter_worker.cleanup(),
                self.company_worker.cleanup()
            )
    
    async def _enrich_single_contact(self, contact: Dict) -> ContactEnrichmentResult:
        """Enrich a single contact across all sources"""
        email = contact.get('email', '')
        name = contact.get('name', '')
        company = contact.get('company', '')
        
        # Parallel enrichment across sources
        linkedin_task = self.linkedin_worker.enrich_contact(name, company)
        twitter_task = self.twitter_worker.enrich_contact(name, email)
        company_task = self.company_worker.enrich_company(company) if company else None
        
        # Gather results
        tasks = [linkedin_task, twitter_task]
        if company_task:
            tasks.append(company_task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results
        linkedin_data = results[0] if not isinstance(results[0], Exception) else None
        twitter_data = results[1] if not isinstance(results[1], Exception) else None
        company_data = results[2] if len(results) > 2 and not isinstance(results[2], Exception) else None
        
        # Calculate confidence score
        confidence = self._calculate_enrichment_confidence(linkedin_data, twitter_data, company_data)
        
        return ContactEnrichmentResult(
            email=email,
            linkedin_data=linkedin_data,
            twitter_data=twitter_data,
            company_data=company_data,
            enrichment_timestamp=datetime.utcnow(),
            confidence_score=confidence
        )
    
    def _calculate_enrichment_confidence(self, linkedin: Dict, twitter: Dict, company: Dict) -> float:
        """Calculate confidence score for enrichment data"""
        score = 0.0
        sources = 0
        
        if linkedin and linkedin.get('profileUrl'):
            score += 0.4
            sources += 1
        
        if twitter and twitter.get('handle'):
            score += 0.3
            sources += 1
        
        if company and company.get('title'):
            score += 0.3
            sources += 1
        
        # Bonus for multiple sources
        if sources >= 2:
            score = min(1.0, score + 0.1)
        
        return score

# Async function to enrich contacts
async def enrich_trusted_contacts(user_id: int, limit: int = 50):
    """Main function to enrich trusted contacts with web intelligence"""
    from models.database import get_db_manager
    
    db_manager = get_db_manager()
    
    # Get trusted contacts that need enrichment
    trusted_contacts = db_manager.get_trusted_contacts(user_id, limit=limit)
    
    # Filter contacts that haven't been enriched recently
    contacts_to_enrich = []
    for contact in trusted_contacts:
        if not hasattr(contact, 'last_enriched') or not contact.last_enriched:
            contacts_to_enrich.append({
                'email': contact.email_address,
                'name': contact.name,
                'company': None  # Extract from email domain if needed
            })
    
    if not contacts_to_enrich:
        logger.info("No contacts need enrichment")
        return
    
    logger.info(f"Enriching {len(contacts_to_enrich)} contacts with web intelligence")
    
    # Run enrichment
    orchestrator = ContactEnrichmentOrchestrator()
    enriched_results = await orchestrator.enrich_contacts_batch(contacts_to_enrich)
    
    # Save enrichment results to database
    for result in enriched_results:
        person = db_manager.find_person_by_email(user_id, result.email)
        if person:
            enrichment_data = {
                'linkedin_url': result.linkedin_data.get('profileUrl') if result.linkedin_data else None,
                'title': result.linkedin_data.get('title') if result.linkedin_data else None,
                'company': result.linkedin_data.get('company') if result.linkedin_data else None,
                'twitter_handle': result.twitter_data.get('handle') if result.twitter_data else None,
                'enrichment_confidence': result.confidence_score,
                'last_enriched': result.enrichment_timestamp
            }
            
            db_manager.update_person_intelligence(user_id, person.id, enrichment_data)
    
    logger.info(f"Successfully enriched {len(enriched_results)} contacts")