ss intelligence for mentioned people
                    'relationship_intelligence': {
                        'context_story': f"Mentioned in discussion about {email.subject or 'business matters'}",
                        'business_relevance': 'mentioned_contact',
                        'strategic_value': 0.3,  # Lower strategic value for mentions
                        'recent_activity': 0,  # No direct activity
                        'communication_frequency': 'mentioned_only',
                        'last_strategic_topic': self._extract_strategic_topic_from_email(email),
                        'collaboration_score': 0.2,
                        'expertise_areas': [],
                        'meeting_participant': False,
                        'communication_style': 'unknown',
                        'avg_urgency': 0.5
                    }
                }
                
                get_db_manager().create_or_update_person(user_id, person_data)
                people_count += 1
                logger.info(f"Created/updated mentioned person: {person_data['name']} ({person_data['email_address']})")
        
        return people_count
    
    def _generate_comprehensive_relationship_story(self, sender_analysis: Dict, email: Email, existing_person=None) -> str:
        """Generate a comprehensive relationship story explaining the full context of this business relationship"""
        try:
            story_parts = []
            
            # Relationship introduction
            name = sender_analysis.get('name', email.sender_name or email.sender.split('@')[0] if email.sender else 'Contact')
            company = sender_analysis.get('company', 'Unknown Company')
            role = sender_analysis.get('role', 'Professional Contact')
            
            story_parts.append(f"ðŸ‘¤ **Professional Contact:** {name}")
            if role and role != 'Professional Contact':
                story_parts.append(f"ðŸ’¼ **Role:** {role}")
            if company and company != 'Unknown Company':
                story_parts.append(f"ðŸ¢ **Company:** {company}")
            
            # Relationship context
            relationship = sender_analysis.get('relationship', 'Business Contact')
            business_relevance = sender_analysis.get('business_relevance', '')
            
            story_parts.append(f"ðŸ¤ **Relationship:** {relationship}")
            if business_relevance:
                story_parts.append(f"ðŸ’¡ **Business Relevance:** {business_relevance}")
            
            # Current communication context
            if email.subject:
                story_parts.append(f"ðŸ“§ **Current Discussion:** '{email.subject}'")
            
            if email.ai_summary and len(email.ai_summary) > 20:
                story_parts.append(f"ðŸ’¬ **Latest Communication:** {email.ai_summary}")
            
            # Historical context if available
            if existing_person:
                total_emails = existing_person.total_emails or 0
                if total_emails > 1:
                    story_parts.append(f"ðŸ“Š **Communication History:** {total_emails} previous email exchanges")
                
                if existing_person.last_interaction:
                    from datetime import datetime, timezone
                    days_since = (datetime.now(timezone.utc) - existing_person.last_interaction).days
                    if days_since < 7:
                        story_parts.append(f"â° **Recent Activity:** Last contacted {days_since} days ago")
                    elif days_since < 30:
                        story_parts.append(f"â° **Regular Contact:** Last contacted {days_since} days ago")
                    else:
                        story_parts.append(f"â° **Reconnection:** Last contacted {days_since} days ago")
            else:
                story_parts.append("ðŸ†• **New Contact:** First recorded interaction")
            
            # Business impact assessment
            if self._is_strategic_communication(email):
                story_parts.append("â­ **Strategic Importance:** This communication has high strategic value")
            
            return "\n".join(story_parts)
            
        except Exception as e:
            logger.error(f"Error generating comprehensive relationship story: {str(e)}")
            return f"Professional contact: {sender_analysis.get('name', 'Business Contact')}"
    
    def _generate_relationship_insights(self, sender_analysis: Dict, email: Email, existing_person=None) -> str:
        """Generate actionable relationship insights and recommendations"""
        try:
            insights = []
            
            # Relationship strength assessment
            name = sender_analysis.get('name', 'Contact')
            
            if existing_person and existing_person.total_emails and existing_person.total_emails > 5:
                insights.append(f"ðŸ”— **Strong Relationship:** You've exchanged {existing_person.total_emails} emails with {name}, indicating an established professional relationship.")
            elif existing_person and existing_person.total_emails and existing_person.total_emails > 1:
                insights.append(f"ðŸŒ± **Developing Relationship:** Building relationship with {name} through ongoing communication.")
            else:
                insights.append(f"ðŸ†• **New Connection:** This is your first recorded interaction with {name}.")
            
            # Business value insights
            business_relevance = sender_analysis.get('business_relevance', '')
            if business_relevance:
                insights.append(f"ðŸ’¼ **Business Value:** {business_relevance}")
            
            # Communication pattern insights
            if self._is_strategic_communication(email):
                insights.append("â­ **Strategic Relevance:** This person is involved in strategic business discussions.")
            
            # Company/role insights
            company = sender_analysis.get('company')
            role = sender_analysis.get('role')
            if company:
                insights.append(f"ðŸ¢ **Company Intelligence:** {name} works at {company}, potentially opening collaboration opportunities.")
            if role:
                insights.append(f"ðŸ‘” **Role Intelligence:** As {role}, they may have decision-making authority or specialized expertise.")
            
            # Engagement recommendations
            if existing_person and existing_person.last_interaction:
                from datetime import datetime, timezone
                days_since = (datetime.now(timezone.utc) - existing_person.last_interaction).days
                if days_since > 60:
                    insights.append(f"ðŸ“… **Engagement Opportunity:** Consider reaching out to {name} to maintain the relationship.")
                elif days_since < 7:
                    insights.append(f"ðŸ”¥ **Active Relationship:** Regular communication with {name} indicates strong engagement.")
            
            # Topic-based insights
            strategic_topic = self._extract_strategic_topic_from_email(email)
            if strategic_topic:
                insights.append(f"ðŸŽ¯ **Topic Expertise:** {name} is engaged in discussions about {strategic_topic}.")
            
            return "\n".join(insights)
            
        except Exception as e:
            logger.error(f"Error generating relationship insights: {str(e)}")
            return f"Professional relationship with valuable business context."
    
    def _generate_mentioned_person_relationship_story(self, person_info: Dict, email: Email, existing_person=None) -> str:
        """Generate relationship story for people mentioned in emails"""
        try:
            story_parts = []
            
            name = person_info.get('name', person_info.get('email', 'Unknown').split('@')[0])
            story_parts.append(f"ðŸ‘¤ **Mentioned Contact:** {name}")
            
            # Context of mention
            mentioned_context = person_info.get('mentioned_context', '')
            if mentioned_context:
                story_parts.append(f"ðŸ’¬ **Mentioned In Context:** {mentioned_context}")
            
            # Business relevance
            business_relevance = person_info.get('business_relevance', '')
            if business_relevance:
                story_parts.append(f"ðŸ’¼ **Business Relevance:** {business_relevance}")
            
            # Email context
            if email.subject:
                story_parts.append(f"ðŸ“§ **Discussion Context:** Mentioned in '{email.subject}'")
            
            # Historical context if available
            if existing_person and existing_person.total_emails:
                story_parts.append(f"ðŸ“Š **Previous Contact:** {existing_person.total_emails} direct communications on record")
            else:
                story_parts.append("ðŸ“ **Indirect Contact:** Known through mentions in communications")
            
            return "\n".join(story_parts)
            
        except Exception as e:
            logger.error(f"Error generating mentioned person story: {str(e)}")
            return f"Contact mentioned in business communications."
    
    def _generate_mentioned_person_insights(self, person_info: Dict, email: Email, existing_person=None) -> str:
        """Generate insights for people mentioned in emails"""
        try:
            insights = []
            
            name = person_info.get('name', 'Contact')
            
            # Mention analysis
            insights.append(f"ðŸ’­ **Indirect Intelligence:** {name} was mentioned in business communications, indicating relevance to your work.")
            
            # Business context
            business_relevance = person_info.get('business_relevance', '')
            if business_relevance:
                insights.append(f"ðŸŽ¯ **Strategic Value:** {business_relevance}")
            
            # Potential for direct engagement
            if person_info.get('email'):
                insights.append(f"ðŸ“§ **Engagement Opportunity:** Consider direct outreach to {name} for collaboration or information.")
            
            # Company intelligence
            company = person_info.get('company')
            if company:
                insights.append(f"ðŸ¢ **Company Connection:** {name} at {company} may represent partnership or business opportunities.")
            
            return "\n".join(insights)
            
        except Exception as e:
            logger.error(f"Error generating mentioned person insights: {str(e)}")
            return f"Mentioned in business context with potential strategic value."
    
    def _process_high_quality_tasks(self, user_id: int, email_id: int, tasks_data: List[Dict]) -> int:
        """Process and create high-quality tasks with COMPREHENSIVE CONTEXT STORIES"""
        tasks_created = 0
        
        # Get the source email for rich context generation
        with get_db_manager().get_session() as session:
            source_email = session.query(Email).filter(Email.id == email_id).first()
            if not source_email:
                logger.error(f"Could not find source email with ID {email_id}")
                return 0
        
        for task_data in tasks_data:
            try:
                # Enhanced quality validation
                description = task_data.get('description', '').strip()
                confidence = task_data.get('confidence', 0.0)
                
                if len(description) < 5 or confidence < self.min_confidence_score:
                    logger.debug(f"Task rejected: description='{description}', confidence={confidence}")
                    continue
                
                # GENERATE COMPREHENSIVE CONTEXT STORY
                comprehensive_context_story = self._generate_comprehensive_task_context_story(task_data, source_email)
                
                # GENERATE DETAILED TASK MEANING
                detailed_task_meaning = self._generate_detailed_task_meaning(task_data, source_email)
                
                # GENERATE COMPREHENSIVE IMPORTANCE ANALYSIS  
                comprehensive_importance_analysis = self._generate_comprehensive_importance_analysis(task_data, source_email)
                
                # GENERATE COMPREHENSIVE ORIGIN DETAILS
                comprehensive_origin_details = self._generate_comprehensive_origin_details(task_data, source_email)
                
                # Parse due date with better handling
                due_date = None
                due_date_text = task_data.get('due_date_text', '')
                if task_data.get('due_date'):
                    due_date = self._parse_due_date(task_data['due_date'])
                
                # Create enhanced task with comprehensive context
                enhanced_task_data = {
                    'description': description,
                    'assignee': task_data.get('assignee'),
                    'due_date': due_date,
                    'due_date_text': due_date_text,
                    'priority': task_data.get('priority', 'medium'),
                    'status': 'pending',
                    'category': task_data.get('category', 'action_item'),
                    'confidence': confidence,
                    'source_text': task_data.get('business_context', ''),
                    'context': task_data.get('business_context', ''),
                    'email_id': email_id,
                    'source_email_subject': source_email.subject,
                    'ai_version': self.version,
                    
                    # COMPREHENSIVE CONTEXT FIELDS - This is what makes tasks rich and detailed
                    'comprehensive_context_story': comprehensive_context_story,
                    'detailed_task_meaning': detailed_task_meaning,
                    'comprehensive_importance_analysis': comprehensive_importance_analysis,
                    'comprehensive_origin_details': comprehensive_origin_details,
                    
                    # Enhanced metadata for frontend intelligence
                    'business_intelligence': {
                        'entity_connections': 1 if source_email.sender else 0,
                        'source_quality': 'high' if source_email.ai_summary else 'medium',
                        'ai_confidence': confidence,
                        'cross_referenced': True,
                        'relationship_strength': 1,  # Will be enhanced based on sender frequency
                        'business_impact_score': confidence * 0.8,  # Strategic importance estimate
                        'action_clarity': 'high' if len(description) > 20 else 'medium',
                        'contextual_richness': 'comprehensive'
                    }
                }
                
                task = get_db_manager().create_or_update_task(user_id, enhanced_task_data)
                if task:
                    tasks_created += 1
                    logger.info(f"Created comprehensive task: {description[:50]}...")
                
            except Exception as e:
                logger.error(f"Failed to create enhanced task: {str(e)}")
                continue
        
        return tasks_created
    
    def _generate_comprehensive_task_context_story(self, task_data: Dict, source_email: Email) -> str:
        """Generate a comprehensive context story explaining the full background of this task"""
        try:
            # Build rich narrative about the task context
            story_parts = []
            
            # Email source context
            if source_email:
                sender_name = source_email.sender_name or source_email.sender.split('@')[0] if source_email.sender else "someone"
                
                # Timing context
                if source_email.email_date:
                    from datetime import datetime, timezone
                    days_ago = (datetime.now(timezone.utc) - source_email.email_date).days
                    if days_ago == 0:
                        timing = f"today ({source_email.email_date.strftime('%I:%M %p')})"
                    elif days_ago == 1:
                        timing = f"yesterday ({source_email.email_date.strftime('%I:%M %p')})"
                    elif days_ago < 7:
                        timing = f"{days_ago} days ago ({source_email.email_date.strftime('%A, %I:%M %p')})"
                    else:
                        timing = source_email.email_date.strftime('%B %d at %I:%M %p')
                else:
                    timing = "recently"
                
                story_parts.append(f"ðŸ“§ **Email from:** {sender_name}")
                story_parts.append(f"ðŸ“… **Timing:** Received {timing}")
                
                if source_email.subject:
                    story_parts.append(f"ðŸ“ **Subject:** '{source_email.subject}'")
                
                # Email content context
                if source_email.ai_summary and len(source_email.ai_summary) > 20:
                    story_parts.append(f"ðŸ’¬ **Email Summary:** {source_email.ai_summary}")
                
                # Business category if available
                if hasattr(source_email, 'ai_category') and source_email.ai_category:
                    story_parts.append(f"ðŸ¢ **Business Category:** {source_email.ai_category}")
            
            # Task-specific context
            business_context = task_data.get('business_context', '')
            if business_context:
                story_parts.append(f"ðŸŽ¯ **Business Impact:** {business_context}")
            
            # Success criteria if available
            success_criteria = task_data.get('success_criteria', '')
            if success_criteria:
                story_parts.append(f"âœ… **Success Criteria:** {success_criteria}")
            
            return "\n".join(story_parts)
            
        except Exception as e:
            logger.error(f"Error generating comprehensive task context: {str(e)}")
            return f"Task from email communication requiring attention."
    
    def _generate_detailed_task_meaning(self, task_data: Dict, source_email: Email) -> str:
        """Generate detailed explanation of what this task actually means and how to complete it"""
        try:
            explanation_parts = []
            description = task_data.get('description', '')
            description_lower = description.lower()
            
            # Analyze the type of action required
            if any(word in description_lower for word in ['call', 'phone', 'ring']):
                explanation_parts.append("ðŸ”” **Action Type:** You need to make a phone call")
                explanation_parts.append(f"ðŸ“ž **Specific Task:** {description}")
                explanation_parts.append("ðŸ“‹ **Steps to Complete:**")
                explanation_parts.append("   1. Find contact information")
                explanation_parts.append("   2. Prepare talking points based on email context")
                explanation_parts.append("   3. Make the call")
                explanation_parts.append("   4. Follow up if needed")
                
            elif any(word in description_lower for word in ['email', 'send', 'reply', 'respond']):
                explanation_parts.append("âœ‰ï¸ **Action Type:** You need to send an email or document")
                explanation_parts.append(f"ðŸ“§ **Specific Task:** {description}")
                explanation_parts.append("ðŸ“‹ **Steps to Complete:**")
                explanation_parts.append("   1. Review the original email context")
                explanation_parts.append("   2. Draft your response/email")
                explanation_parts.append("   3. Include relevant information or attachments")
                explanation_parts.append("   4. Send and track response")
                
            elif any(word in description_lower for word in ['schedule', 'book', 'meeting', 'appointment']):
                explanation_parts.append("ðŸ“… **Action Type:** You need to arrange a meeting or appointment")
                explanation_parts.append(f"ðŸ—“ï¸ **Specific Task:** {description}")
                explanation_parts.append("ðŸ“‹ **Steps to Complete:**")
                explanation_parts.append("   1. Check your calendar availability")
                explanation_parts.append("   2. Propose meeting times")
                explanation_parts.append("   3. Send calendar invite")
                explanation_parts.append("   4. Confirm attendance")
                
            elif any(word in description_lower for word in ['review', 'check', 'examine', 'evaluate']):
                explanation_parts.append("ðŸ” **Action Type:** You need to examine or evaluate something")
                explanation_parts.append(f"ðŸ“‹ **Specific Task:** {description}")
                
            elif any(word in description_lower for word in ['follow up', 'followup', 'follow-up']):
                explanation_parts.append("â° **Action Type:** You need to check back on something or continue a conversation")
                explanation_parts.append(f"ðŸ”„ **Specific Task:** {description}")
                
            elif any(word in description_lower for word in ['complete', 'finish', 'deliver', 'submit']):
                explanation_parts.append("âœ… **Action Type:** You need to complete or deliver something")
                explanation_parts.append(f"ðŸŽ¯ **Specific Task:** {description}")
                
            else:
                explanation_parts.append("âš¡ **Action Type:** General business action required")
                explanation_parts.append(f"ðŸ“ **Specific Task:** {description}")
            
            # Add email context for better understanding
            if source_email and source_email.ai_summary:
                explanation_parts.append(f"ðŸ“– **Background Context:** {source_email.ai_summary}")
            
            return "\n".join(explanation_parts)
            
        except Exception as e:
            logger.error(f"Error generating detailed task meaning: {str(e)}")
            return f"Action required: {task_data.get('description', 'Task completion needed')}"
    
    def _generate_comprehensive_importance_analysis(self, task_data: Dict, source_email: Email) -> str:
        """Generate comprehensive analysis of why this task is important"""
        try:
            importance_factors = []
            
            # Priority analysis
            priority = task_data.get('priority', 'medium')
            if priority == 'high':
                importance_factors.append("ðŸš¨ **Priority Level:** This is marked as HIGH PRIORITY - requires immediate attention")
            elif priority == 'medium':
                importance_factors.append("âš ï¸ **Priority Level:** This is medium priority - should be completed soon")
            else:
                importance_factors.append("ðŸ“ **Priority Level:** This is standard priority")
            
            # AI confidence analysis
            confidence = task_data.get('confidence', 0.0)
            if confidence > 0.9:
                importance_factors.append("ðŸ¤– **AI Confidence:** VERY HIGH (95%+) - This is definitely a real action item")
            elif confidence > 0.8:
                importance_factors.append("ðŸ¤– **AI Confidence:** HIGH (80%+) - This is very likely a real action item")
            elif confidence > 0.6:
                importance_factors.append("ðŸ¤– **AI Confidence:** MEDIUM (60%+) - This appears to be an action item")
            
            # Business impact
            business_context = task_data.get('business_context', '')
            if business_context:
                importance_factors.append(f"ðŸ’¼ **Business Impact:** {business_context}")
            
            # Email source importance
            if source_email:
                if hasattr(source_email, 'strategic_importance') and source_email.strategic_importance and source_email.strategic_importance > 0.7:
                    importance_factors.append("â­ **Strategic Value:** The source email was marked as strategically important")
                
                if hasattr(source_email, 'urgency_score') and source_email.urgency_score and source_email.urgency_score > 0.7:
                    importance_factors.append("ðŸ’¼ **Business Impact:** The original email was marked as urgent")
                
                if hasattr(source_email, 'action_required') and source_email.action_required:
                    importance_factors.append("ðŸ’¼ **Business Impact:** The original email explicitly requested action")
            
            # Due date urgency
            due_date_text = task_data.get('due_date_text', '')
            if due_date_text:
                importance_factors.append(f"â° **Timing:** Deadline mentioned: {due_date_text}")
            
            return "\n".join(importance_factors)
            
        except Exception as e:
            logger.error(f"Error generating importance analysis: {str(e)}")
            return "Standard business task requiring attention."
    
    def _generate_comprehensive_origin_details(self, task_data: Dict, source_email: Email) -> str:
        """Generate comprehensive details about where this task originated"""
        try:
            origin_details = []
            
            if source_email:
                # Source identification
                if source_email.sender_name and source_email.sender:
                    origin_details.append(f"ðŸ“§ **Original Email From:** {source_email.sender_name} ({source_email.sender})")
                elif source_email.sender:
                    origin_details.append(f"ðŸ“§ **Original Email From:** {source_email.sender}")
                
                # Email details
                if source_email.subject:
                    origin_details.append(f"ðŸ“„ **Email Subject:** '{source_email.subject}'")
                
                if source_email.email_date:
                    origin_details.append(f"ðŸ“… **Received:** {source_email.email_date.strftime('%A, %B %d, %Y at %I:%M %p')}")
                
                # Email content preview
                if hasattr(source_email, 'body_text') and source_email.body_text:
                    preview = source_email.body_text[:300].strip()
                    if len(source_email.body_text) > 300:
                        preview += "..."
                    origin_details.append(f"ðŸ“ **Email Content Preview:** {preview}")
                elif source_email.ai_summary:
                    origin_details.append(f"ðŸ“ **Email Content Summary:** {source_email.ai_summary}")
                
                # Processing details
                if source_email.processed_at:
                    origin_details.append(f"ðŸ¤– **AI Processed:** {source_email.processed_at.strftime('%Y-%m-%d at %I:%M %p')}")
                
                # Email metadata
                metadata = []
                if hasattr(source_email, 'thread_id') and source_email.thread_id:
                    metadata.append("Part of email thread")
                if hasattr(source_email, 'labels') and source_email.labels:
                    metadata.append(f"Gmail labels: {', '.join(source_email.labels[:3])}")
                if metadata:
                    origin_details.append(f"ðŸ“Š **Email Metadata:** {'; '.join(metadata)}")
            else:
                origin_details.append("ðŸ“ **Task Origin:** Created manually or from unknown source")
                origin_details.append("â„¹ï¸ **Note:** This task was not automatically extracted from an email")
            
            return "\n".join(origin_details)
            
        except Exception as e:
            logger.error(f"Error generating origin details: {str(e)}")
            return "Task created from email communication."
    
    def _prepare_enhanced_email_context(self, email: Email, user) -> str:
        """Prepare comprehensive email context for Claude analysis"""
        timestamp = email.email_date.strftime('%Y-%m-%d %H:%M') if email.email_date else 'Unknown'
        
        context = f"""EMAIL ANALYSIS REQUEST

Recipient: {user.email} ({user.name})
From: {email.sender_name or 'Unknown'} <{email.sender}>
Date: {timestamp}
Subject: {email.subject}

Email Content:
{email.body_clean or email.snippet}

Additional Context:
- Recipients: {', '.join(email.recipient_emails) if email.recipient_emails else 'Not specified'}
- Thread ID: {email.thread_id}
- Email Labels: {', '.join(email.labels) if email.labels else 'None'}
- Message Type: {email.message_type or 'Unknown'}
- Priority Score: {email.priority_score or 'Not calculated'}
"""
        return context
    
    def _update_email_with_insights(self, email: Email, analysis: Dict):
        """Update email record with Claude insights"""
        with get_db_manager().get_session() as session:
            email_record = session.query(Email).filter(Email.id == email.id).first()
            if email_record:
                email_record.ai_summary = analysis.get('summary')
                email_record.ai_category = analysis.get('ai_category')
                email_record.sentiment_score = analysis.get('sentiment_score')
                email_record.urgency_score = analysis.get('urgency_score')
                email_record.key_insights = analysis.get('business_insights')
                email_record.topics = analysis.get('topics')
                email_record.action_required = analysis.get('action_required', False)
                email_record.follow_up_required = analysis.get('follow_up_required', False)
                
                session.commit()
    
    def _process_project_insights(self, user_id: int, project_data: Dict, email: Email) -> Optional[Project]:
        """Process and update project information - SAFE VERSION"""
        if not project_data or not project_data.get('name'):
            return None
        
        try:
            project_info = {
                'name': project_data['name'],
                'slug': self._create_slug(project_data['name']),
                'description': project_data.get('description'),
                'category': project_data.get('category'),
                'priority': project_data.get('priority', 'medium'),
                'status': project_data.get('status', 'active'),
                'key_topics': project_data.get('key_topics', []),
                'stakeholders': project_data.get('stakeholders', []),
                'ai_version': self.version
            }
            
            return get_db_manager().create_or_update_project(user_id, project_info)
            
        except Exception as e:
            logger.error(f"Error processing project insights: {str(e)}")
            return None
    
    def _create_slug(self, name: str) -> str:
        """Create URL-friendly slug from name"""
        return re.sub(r'[^a-zA-Z0-9]+', '-', name.lower()).strip('-')
    
    def _parse_due_date(self, date_str: str) -> Optional[datetime]:
        """Parse due date string into datetime"""
        if not date_str:
            return None
        
        try:
            return datetime.strptime(date_str, '%Y-%m-%d')
        except:
            return None
    
    def get_business_knowledge_summary(self, user_email: str) -> Dict:
        """Get comprehensive business knowledge summary with quality synthesis"""
        try:
            user = get_db_manager().get_user_by_email(user_email)
            if not user:
                return {'success': False, 'error': 'User not found'}
            
            # Get all processed emails with quality filtering
            emails = get_db_manager().get_user_emails(user.id, limit=1000)
            projects = get_db_manager().get_user_projects(user.id, limit=200)
            people = get_db_manager().get_user_people(user.id, limit=500)
            
            # Filter for high-quality insights only
            quality_emails = [e for e in emails if e.ai_summary and len(e.ai_summary) > self.min_insight_length]
            human_contacts = [p for p in people if not self._is_non_human_contact(p.email_address or '')]
            substantial_projects = [p for p in projects if p.description and len(p.description) > self.min_insight_length]
            
            # Synthesize high-quality business insights
            strategic_decisions = []
            business_opportunities = []
            key_challenges = []
            competitive_insights = []
            
            for email in quality_emails:
                if email.key_insights and isinstance(email.key_insights, dict):
                    insights = email.key_insights
                    
                    # Extract strategic-level insights only
                    decisions = insights.get('key_decisions', [])
                    strategic_decisions.extend([d for d in decisions if len(d) > self.min_insight_length])
                    
                    opportunities = insights.get('strategic_opportunities', insights.get('opportunities', []))
                    business_opportunities.extend([o for o in opportunities if len(o) > self.min_insight_length])
                    
                    challenges = insights.get('business_challenges', insights.get('challenges', []))
                    key_challenges.extend([c for c in challenges if len(c) > self.min_insight_length])
                    
                    competitive = insights.get('competitive_intelligence', [])
                    competitive_insights.extend([ci for ci in competitive if len(ci) > self.min_insight_length])
            
            # Get meaningful topics
            topics = get_db_manager().get_user_topics(user.id, limit=1000)
            business_topics = [topic.name for topic in topics if topic.is_official or 
                              (topic.description and len(topic.description) > 10)]
            
            return {
                'success': True,
                'user_email': user_email,
                'business_knowledge': {
                    'summary_stats': {
                        'quality_emails_analyzed': len(quality_emails),
                        'human_contacts': len(human_contacts),
                        'substantial_projects': len(substantial_projects),
                        'strategic_insights': len(strategic_decisions) + len(business_opportunities) + len(key_challenges)
                    },
                    'strategic_intelligence': {
                        'key_decisions': self._deduplicate_and_rank(strategic_decisions)[:8],  # Top 8 strategic decisions
                        'business_opportunities': self._deduplicate_and_rank(business_opportunities)[:8],
                        'key_challenges': self._deduplicate_and_rank(key_challenges)[:8],
                        'competitive_intelligence': self._deduplicate_and_rank(competitive_insights)[:5]
                    },
                    'business_topics': business_topics[:15],  # Top 15 business topics
                    'network_intelligence': {
                        'total_human_contacts': len(human_contacts),
                        'active_projects': len([p for p in substantial_projects if p.status == 'active']),
                        'project_categories': list(set([p.category for p in substantial_projects if p.category]))
                    }
                }
            }
            
        except Exception as e:
            logger.error(f"Failed to get business knowledge for {user_email}: {str(e)}")
            return {'success': False, 'error': str(e)}

    def get_chat_knowledge_summary(self, user_email: str) -> Dict:
        """Get comprehensive knowledge summary for chat interface with enhanced context"""
        try:
            user = get_db_manager().get_user_by_email(user_email)
            if not user:
                return {'success': False, 'error': 'User not found'}
            
            # Get all processed data with quality filters
            emails = get_db_manager().get_user_emails(user.id, limit=1000)
            projects = get_db_manager().get_user_projects(user.id, limit=200)
            people = get_db_manager().get_user_people(user.id, limit=500)
            topics = get_db_manager().get_user_topics(user.id, limit=1000)
            
            # GET CALENDAR EVENTS FOR KNOWLEDGE BASE
            now = datetime.now(timezone.utc)
            calendar_events = get_db_manager().get_user_calendar_events(
                user.id, 
                start_date=now - timedelta(days=30),  # Past 30 days for context
                end_date=now + timedelta(days=60),    # Next 60 days for planning
                limit=200
            )
            
            # Filter for high-quality content
            quality_emails = [e for e in emails if e.ai_summary and len(e.ai_summary) > self.min_insight_length]
            human_contacts = [p for p in people if not self._is_non_human_contact(p.email_address or '') and p.name]
            
            # Compile rich contacts with enhanced professional context
            rich_contacts = []
            for person in human_contacts[:15]:  # Top 15 human contacts
                # Create rich professional story
                professional_story = self._create_professional_story(person, quality_emails)
                
                contact_info = {
                    'name': person.name,
                    'email': person.email_address,
                    'title': person.title or person.role,
                    'company': person.company,
                    'relationship': person.relationship_type,
                    'story': professional_story,
                    'total_emails': person.total_emails or 0,
                    'last_interaction': person.last_interaction.isoformat() if person.last_interaction else None,
                    'importance_score': person.importance_level or 0.5
                }
                rich_contacts.append(contact_info)
            
            # Enhanced business intelligence compilation
            business_decisions = []
            opportunities = []
            challenges = []
            
            for email in quality_emails:
                if email.key_insights and isinstance(email.key_insights, dict):
                    insights = email.key_insights
                    
                    # Enhanced insight extraction with context
                    decisions = insights.get('key_decisions', [])
                    for decision in decisions:
                        if len(decision) > self.min_insight_length:
                            business_decisions.append({
                                'decision': decision,
                                'context': email.ai_summary,
                                'sender': email.sender_name or email.sender,
                                'date': email.email_date.isoformat() if email.email_date else None
                            })
                    
                    opps = insights.get('strategic_opportunities', insights.get('opportunities', []))
                    for opp in opps:
                        if len(opp) > self.min_insight_length:
                            opportunities.append({
                                'opportunity': opp,
                                'context': email.ai_summary,
                                'source': email.sender_name or email.sender,
                                'date': email.email_date.isoformat() if email.email_date else None
                            })
                    
                    chals = insights.get('business_challenges', insights.get('challenges', []))
                    for chal in chals:
                        if len(chal) > self.min_insight_length:
                            challenges.append({
                                'challenge': chal,
                                'context': email.ai_summary,
                                'source': email.sender_name or email.sender,
                                'date': email.email_date.isoformat() if email.email_date else None
                            })
            
            # Enhanced topic knowledge with rich contexts
            topic_knowledge = {
                'all_topics': [topic.name for topic in topics if topic.is_official or 
                              (topic.description and len(topic.description) > 10)],
                'official_topics': [topic.name for topic in topics if topic.is_official],
                'topic_contexts': {}
            }
            
            for topic in topics:
                if topic.is_official or (topic.description and len(topic.description) > 10):
                    topic_emails = [email for email in quality_emails if email.topics and topic.name in email.topics]
                    contexts = []
                    for email in topic_emails[:3]:  # Top 3 emails per topic
                        if email.ai_summary:
                            contexts.append({
                                'summary': email.ai_summary,
                                'sender': email.sender_name or email.sender,
                                'date': email.email_date.isoformat() if email.email_date else None,
                                'email_subject': email.subject
                            })
                    topic_knowledge['topic_contexts'][topic.name] = contexts
            
            # Enhanced statistics
            summary_stats = {
                'total_emails_analyzed': len(quality_emails),
                'rich_contacts': len(rich_contacts),
                'business_decisions': len(business_decisions),
                'opportunities_identified': len(opportunities),
                'challenges_tracked': len(challenges),
                'active_projects': len([p for p in projects if p.status == 'active']),
                'official_topics': len([t for t in topics if t.is_official]),
                'calendar_events': len(calendar_events),
                'upcoming_meetings': len([e for e in calendar_events if e.start_time and e.start_time > now]),
                'recent_meetings': len([e for e in calendar_events if e.start_time and e.start_time < now])
            }
            
            # Process calendar intelligence for knowledge base
            calendar_intelligence = self._extract_calendar_intelligence(calendar_events, people, now)
            
            return {
                'success': True,
                'user_email': user_email,
                'knowledge_base': {
                    'summary_stats': summary_stats,
                    'rich_contacts': rich_contacts,
                    'business_intelligence': {
                        'recent_decisions': sorted(business_decisions, 
                                                 key=lambda x: x['date'] or '', reverse=True)[:8],
                        'top_opportunities': sorted(opportunities,
                                                  key=lambda x: x['date'] or '', reverse=True)[:8],
                        'current_challenges': sorted(challenges,
                                                   key=lambda x: x['date'] or '', reverse=True)[:8]
                    },
                    'topic_knowledge': topic_knowledge,
                    'projects_summary': [
                        {
                            'name': project.name,
                            'description': project.description,
                            'status': project.status,
                            'priority': project.priority,
                            'stakeholders': project.stakeholders or [],
                            'key_topics': project.key_topics or []
                        }
                        for project in projects if project.description and len(project.description) > self.min_insight_length
                    ][:10],  # Top 10 substantial projects
                    'calendar_events': calendar_events,
                    'calendar_intelligence': calendar_intelligence
                }
            }
        
        except Exception as e:
            logger.error(f"Failed to get chat knowledge for {user_email}: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _create_professional_story(self, person: Person, emails: List[Email]) -> str:
        """Create a rich professional story for a contact based on email interactions"""
        try:
            # Find emails from this person
            person_emails = [e for e in emails if e.sender and person.email_address and 
                           e.sender.lower() == person.email_address.lower()]
            
            if not person_emails:
                return f"Professional contact with {person.relationship_type or 'business'} relationship."
            
            # Analyze communication patterns and content
            total_emails = len(person_emails)
            recent_emails = sorted(person_emails, key=lambda x: x.email_date or datetime.min, reverse=True)[:3]
            
            # Extract key themes from their communication
            themes = []
            for email in recent_emails:
                if email.ai_summary and len(email.ai_summary) > 20:
                    themes.append(email.ai_summary)
            
            # Create professional narrative
            story_parts = []
            
            if person.company and person.title:
                story_parts.append(f"{person.title} at {person.company}")
            elif person.company:
                story_parts.append(f"Works at {person.company}")
            elif person.title:
                story_parts.append(f"{person.title}")
            
            if total_emails > 1:
                story_parts.append(f"Active correspondence with {total_emails} substantive emails")
            
            if themes:
                story_parts.append(f"Recent discussions: {'; '.join(themes[:2])}")
            
            if person.relationship_type:
                story_parts.append(f"Relationship: {person.relationship_type}")
            
            return '. '.join(story_parts) if story_parts else "Professional business contact"
            
        except Exception as e:
            logger.error(f"Error creating professional story: {str(e)}")
            return "Professional business contact"
    
    def _deduplicate_and_rank(self, items: List[str]) -> List[str]:
        """Deduplicate similar items and rank by relevance"""
        if not items:
            return []
        
        # Simple deduplication by similarity (basic approach)
        unique_items = []
        for item in items:
            # Check if this item is too similar to existing ones
            is_duplicate = False
            for existing in unique_items:
                # Simple similarity check - if 70% of words overlap, consider duplicate
                item_words = set(item.lower().split())
                existing_words = set(existing.lower().split())
                
                if len(item_words) > 0 and len(existing_words) > 0:
                    overlap = len(item_words & existing_words)
                    similarity = overlap / min(len(item_words), len(existing_words))
                    if similarity > 0.7:
                        is_duplicate = True
                        break
            
            if not is_duplicate:
                unique_items.append(item)
        
        # Rank by length and specificity (longer, more specific items are often better)
        unique_items.sort(key=lambda x: (len(x), len(x.split())), reverse=True)
        
        return unique_items

    def _get_user_business_context(self, user_id: int) -> Dict:
        """Get existing business context to enhance AI analysis"""
        try:
            # Get existing high-quality projects
            projects = get_db_manager().get_user_projects(user_id, limit=50)
            project_context = [p.name for p in projects if p.description and len(p.description) > 20]
            
            # Get existing high-quality people
            people = get_db_manager().get_user_people(user_id, limit=100)
            people_context = [f"{p.name} ({p.role or 'Unknown role'}) at {p.company or 'Unknown company'}" 
                             for p in people if p.name and not self._is_non_human_contact(p.email_address or '')]
            
            # Get existing topics
            topics = get_db_manager().get_user_topics(user_id, limit=100)
            topic_context = [t.name for t in topics if t.is_official]
            
            return {
                'existing_projects': project_context[:10],  # Top 10 projects
                'key_contacts': people_context[:20],  # Top 20 human contacts
                'official_topics': topic_context[:15]  # Top 15 official topics
            }
        except Exception as e:
            logger.error(f"Failed to get user business context: {str(e)}")
            return {'existing_projects': [], 'key_contacts': [], 'official_topics': []}

    def _is_non_human_contact(self, email_address: str) -> bool:
        """Determine if an email address belongs to a non-human sender - BALANCED VERSION"""
        if not email_address:
            return True
            
        email_lower = email_address.lower()
        
        # FOCUSED: Only filter obvious automation, preserve business contacts
        definite_non_human_patterns = [
            'noreply', 'no-reply', 'donotreply', 'do-not-reply', 
            'mailer-daemon', 'postmaster@', 'daemon@', 'bounce@',
            'robot@', 'bot@', 'automated@', 'system@notification',
            'newsletter@', 'digest@', 'updates@notifications'
        ]
        
        # Check against definite non-human patterns only
        for pattern in definite_non_human_patterns:
            if pattern in email_lower:
                return True
        
        # SPECIFIC: Only filter major newsletter/automation services
        automation_domains = [
            'substack.com', 'beehiiv.com', 'mailchimp.com', 'constantcontact.com',
            'campaign-archive.com', 'sendgrid.net', 'mailgun.org', 'mandrill.com'
        ]
        
        for domain in automation_domains:
            if domain in email_lower:
                return True
        
        # PRESERVE: Keep business contacts that might use standard business email patterns
        # Removed: 'admin@', 'info@', 'contact@', 'help@', 'service@', 'team@', 'hello@', 'hi@'
        # Removed: 'linkedin.com', 'facebook.com', etc. - people use these for business
                
        return False

    def _filter_quality_emails_debug(self, emails: List[Email], user_email: str) -> List[Email]:
        """Enhanced filtering for quality-focused email processing - ULTRA PERMISSIVE DEBUG VERSION"""
        quality_emails = []
        
        for email in emails:
            logger.debug(f"Evaluating email from {email.sender} with subject: {email.subject}")
            
            # Skip emails from the user themselves - check both email and name
            if email.sender and user_email.lower() in email.sender.lower():
                logger.debug(f"Skipping email from user themselves: {email.sender}")
                continue
            
            # ULTRA PERMISSIVE: Accept almost all emails for debugging
            # Only skip completely empty emails
            content = email.body_clean or email.snippet or email.subject or ''
            if len(content.strip()) < 3:  # Ultra permissive - just need any content
                logger.debug(f"Skipping email with no content: {len(content)} chars")
                continue
                
            logger.debug(f"Email passed ultra-permissive quality filters: {email.sender}")
            quality_emails.append(email)
        
        logger.info(f"Quality filtering (DEBUG MODE): {len(quality_emails)} emails passed out of {len(emails)} total")
        return quality_emails

    def _is_obviously_non_human_contact(self, email_address: str) -> bool:
        """RELAXED: Only filter obviously non-human contacts - for debugging"""
        if not email_address:
            return True
            
        email_lower = email_address.lower()
        
        # Only the most obvious non-human patterns
        obvious_non_human_patterns = [
            'noreply', 'no-reply', 'donotreply', 'mailer-daemon',
            'postmaster@', 'daemon@', 'bounce@', 'automated@',
            'robot@', 'bot@'
        ]
        
        # Check against obvious non-human patterns only
        for pattern in obvious_non_human_patterns:
            if pattern in email_lower:
                logger.debug(f"Obvious non-human pattern detected: {pattern} in {email_address}")
                return True
                
        return False

    def _is_obvious_newsletter_or_promotional(self, email: Email) -> bool:
        """RELAXED: Only filter obvious newsletters - for debugging"""
        if not email:
            return True
            
        sender = (email.sender or '').lower()
        subject = (email.subject or '').lower()
        content = (email.body_clean or email.snippet or '').lower()
        
        # Only check for very obvious newsletter patterns
        obvious_newsletter_patterns = [
            'substack.com', 'mailchimp.com', 'beehiiv.com',
            'unsubscribe', 'view in browser', 'manage preferences'
        ]
        
        # Check domain patterns
        for pattern in obvious_newsletter_patterns:
            if pattern in sender or pattern in content:
                logger.debug(f"Obvious newsletter pattern detected: {pattern}")
                return True
                
        return False

    def _validate_analysis_quality_debug(self, analysis: Dict) -> bool:
        """Validate that the analysis meets quality standards - DEBUG VERSION (more permissive)"""
        try:
            # Check strategic value score - very relaxed threshold
            strategic_value = analysis.get('strategic_value_score', 0)
            if strategic_value < 0.3:  # Very relaxed - was 0.5
                logger.debug(f"Analysis rejected - low strategic value: {strategic_value}")
                return False
            
            # Check summary quality - very short minimum
            summary = analysis.get('summary', '')
            if len(summary) < 5:  # Very short minimum
                logger.debug(f"Analysis rejected - summary too short: {len(summary)} chars")
                return False
            
            # Very relaxed trivial content detection
            if len(summary) < 15 and summary.lower().strip() in ['ok', 'thanks', 'got it', 'noted']:
                logger.debug(f"Analysis rejected - trivial content detected: {summary}")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Error validating analysis quality: {str(e)}")
            return False
    
    # Helper methods for comprehensive relationship intelligence
    def _generate_communication_timeline_entry(self, email: Email) -> Dict:
        """Generate a timeline entry for this communication"""
        return {
            'date': email.email_date.isoformat() if email.email_date else None,
            'subject': email.subject,
            'summary': email.ai_summary[:100] + '...' if email.ai_summary and len(email.ai_summary) > 100 else email.ai_summary,
            'urgency': self._assess_email_urgency(email),
            'action_required': self._has_action_required(email),
            'business_category': self._categorize_communication_pattern(email)
        }
    
    def _assess_business_relevance(self, sender_analysis: Dict, email: Email) -> str:
        """Assess the business relevance of this relationship"""
        business_relevance = sender_analysis.get('business_relevance', '')
        if business_relevance:
            return business_relevance
        
        # Fallback assessment based on email content
        if self._is_strategic_communication(email):
            return 'high'
        elif sender_analysis.get('company'):
            return 'medium'
        else:
            return 'standard'
    
    def _calculate_strategic_value(self, sender_analysis: Dict, email: Email) -> float:
        """Calculate strategic value of this relationship"""
        value = 0.5  # Base value
        
        # Company factor
        if sender_analysis.get('company'):
            value += 0.2
        
        # Role factor
        role = sender_analysis.get('role', '').lower()
        if any(keyword in role for keyword in ['director', 'manager', 'ceo', 'founder', 'vp', 'head', 'lead']):
            value += 0.2
        
        # Strategic communication factor
        if self._is_strategic_communication(email):
            value += 0.3
        
        return min(1.0, value)
    
    def _assess_communication_frequency(self, existing_person) -> str:
        """Assess communication frequency pattern"""
        if not existing_person or not existing_person.total_emails:
            return 'new'
        
        total_emails = existing_person.total_emails
        if total_emails >= 20:
            return 'frequent'
        elif total_emails >= 5:
            return 'regular'
        elif total_emails >= 2:
            return 'occasional'
        else:
            return 'minimal'
    
    def _extract_strategic_topic_from_email(self, email: Email) -> str:
        """Extract the main strategic topic from email"""
        if email.subject:
            # Simple extraction of key terms
            subject_lower = email.subject.lower()
            strategic_keywords = ['project', 'meeting', 'proposal', 'partnership', 'deal', 'contract', 'strategy', 'funding', 'launch']
            for keyword in strategic_keywords:
                if keyword in subject_lower:
                    return keyword.capitalize()
        
        # Fallback to business category
        return self._categorize_communication_pattern(email)
    
    def _calculate_collaboration_score(self, sender_analysis: Dict, email: Email) -> float:
        """Calculate collaboration potential score"""
        score = 0.3  # Base score
        
        # Project involvement
        if any(word in (email.ai_summary or '').lower() for word in ['project', 'collaboration', 'work together', 'partnership']):
            score += 0.4
        
        # Role-based collaboration potential
        role = sender_analysis.get('role', '').lower()
        if any(keyword in role for keyword in ['manager', 'director', 'lead', 'coordinator']):
            score += 0.3
        
        return min(1.0, score)
    
    def _extract_expertise_areas(self, email: Email, sender_analysis: Dict) -> List[str]:
        """Extract areas of expertise from communication"""
        expertise_areas = []
        
        # From role
        role = sender_analysis.get('role', '')
        if role:
            expertise_areas.append(role)
        
        # From email content
        if email.ai_summary:
            technical_terms = ['AI', 'machine learning', 'technology', 'software', 'development', 'marketing', 'sales', 'finance', 'strategy']
            content_lower = email.ai_summary.lower()
            for term in technical_terms:
                if term.lower() in content_lower:
                    expertise_areas.append(term)
        
        return list(set(expertise_areas))[:3]  # Limit to top 3
    
    def _is_meeting_participant(self, email: Email) -> bool:
        """Check if this person is likely a meeting participant"""
        if email.subject:
            meeting_indicators = ['meeting', 'call', 'zoom', 'teams', 'conference', 'discussion']
            return any(indicator in email.subject.lower() for indicator in meeting_indicators)
        return False
    
    def _assess_communication_style(self, email: Email) -> str:
        """Assess communication style"""
        if email.subject:
            subject_lower = email.subject.lower()
            if any(word in subject_lower for word in ['urgent', 'asap', 'immediately']):
                return 'urgent'
            elif any(word in subject_lower for word in ['follow up', 'checking in', 'update']):
                return 'collaborative'
            elif any(word in subject_lower for word in ['meeting', 'call', 'discussion']):
                return 'meeting-focused'
        return 'professional'
    
    def _assess_email_urgency(self, email: Email) -> float:
        """Assess urgency of email communication"""
        if email.subject:
            urgent_keywords = ['urgent', 'asap', 'immediately', 'critical', 'emergency']
            subject_lower = email.subject.lower()
            if any(keyword in subject_lower for keyword in urgent_keywords):
                return 0.9
            elif any(keyword in subject_lower for keyword in ['important', 'priority']):
                return 0.7
        return 0.5  # Default moderate urgency
    
    def _extract_strategic_topics_list(self, email: Email) -> List[str]:
        """Extract list of strategic topics from email"""
        topics = []
        
        # From subject
        if email.subject:
            # Extract project names, company names, etc.
            words = email.subject.split()
            for word in words:
                if len(word) > 3 and word[0].isupper():  # Likely proper noun
                    topics.append(word)
        
        # From business categories
        category = self._categorize_communication_pattern(email)
        if category:
            topics.append(category)
        
        return list(set(topics))[:5]  # Limit to top 5
    
    def _categorize_communication_pattern(self, email: Email) -> str:
        """Categorize the communication pattern"""
        if email.subject:
            subject_lower = email.subject.lower()
            if any(word in subject_lower for word in ['meeting', 'call', 'zoom']):
                return 'meeting_coordination'
            elif any(word in subject_lower for word in ['project', 'task', 'deliverable']):
                return 'project_management'
            elif any(word in subject_lower for word in ['follow up', 'status', 'update']):
                return 'status_update'
            elif any(word in subject_lower for word in ['proposal', 'contract', 'agreement']):
                return 'business_development'
        return 'general_business'
    
    def _extract_project_involvement(self, email: Email, sender_analysis: Dict) -> List[Dict]:
        """Extract project involvement information"""
        projects = []
        
        if email.ai_summary:
            # Simple project detection
            summary_lower = email.ai_summary.lower()
            if 'project' in summary_lower:
                projects.append({
                    'project': 'Ongoing Project',
                    'email_date': email.email_date.isoformat() if email.email_date else None,
                    'role': 'collaborator',
                    'context': email.ai_summary[:100] + '...' if len(email.ai_summary) > 100 else email.ai_summary
                })
        
        return projects
    
    def _is_strategic_communication(self, email: Email) -> bool:
        """Check if this is a strategic communication"""
        if hasattr(email, 'strategic_importance') and email.strategic_importance:
            return email.strategic_importance > 0.7
        
        # Fallback analysis
        if email.subject:
            strategic_keywords = ['strategy', 'strategic', 'important', 'critical', 'partnership', 'deal', 'funding', 'board']
            return any(keyword in email.subject.lower() for keyword in strategic_keywords)
        
        return False
    
    def _format_last_strategic_communication(self, email: Email) -> Dict:
        """Format strategic communication details"""
        return {
            'date': email.email_date.isoformat() if email.email_date else None,
            'subject': email.subject,
            'summary': email.ai_summary,
            'importance': getattr(email, 'strategic_importance', 0.8),
            'category': self._categorize_communication_pattern(email),
            'action_required': self._has_action_required(email),
            'urgency': self._assess_email_urgency(email)
        }
    
    def _extract_key_decisions(self, analysis: Dict, email: Email) -> List[str]:
        """Extract key decisions from analysis"""
        decisions = []
        business_insights = analysis.get('business_insights', {})
        if isinstance(business_insights, dict):
            decisions.extend(business_insights.get('key_decisions', []))
        return decisions[:3]  # Limit to top 3
    
    def _extract_opportunities(self, analysis: Dict, email: Email) -> List[str]:
        """Extract opportunities from analysis"""
        opportunities = []
        business_insights = analysis.get('business_insights', {})
        if isinstance(business_insights, dict):
            opportunities.extend(business_insights.get('strategic_opportunities', []))
        return opportunities[:3]  # Limit to top 3
    
    def _extract_challenges(self, analysis: Dict, email: Email) -> List[str]:
        """Extract challenges from analysis"""
        challenges = []
        business_insights = analysis.get('business_insights', {})
        if isinstance(business_insights, dict):
            challenges.extend(business_insights.get('business_challenges', []))
        return challenges[:2]  # Limit to top 2
    
    def _extract_collaboration_projects(self, email: Email, analysis: Dict) -> List[str]:
        """Extract collaboration projects"""
        projects = []
        
        # From project analysis
        project_data = analysis.get('project', {})
        if project_data and project_data.get('name'):
            projects.append(project_data['name'])
        
        # From email content
        if email.subject and 'project' in email.subject.lower():
            projects.append(email.subject)
        
        return list(set(projects))[:3]
    
    def _extract_expertise_indicators(self, email: Email, sender_analysis: Dict) -> List[str]:
        """Extract expertise indicators"""
        indicators = []
        
        # From role
        role = sender_analysis.get('role', '')
        if role:
            indicators.append(role)
        
        # From company
        company = sender_analysis.get('company', '')
        if company:
            indicators.append(f"{company} expertise")
        
        return indicators[:2]
    
    def _calculate_meeting_frequency(self, email: Email) -> int:
        """Calculate meeting frequency indicator"""
        if self._is_meeting_participant(email):
            return 1
        return 0
    
    def _assess_response_reliability(self, existing_person) -> str:
        """Assess response reliability"""
        if not existing_person:
            return 'unknown'
        
        # Simple assessment based on email frequency
        if existing_person.total_emails and existing_person.total_emails >= 5:
            return 'reliable'
        elif existing_person.total_emails and existing_person.total_emails >= 2:
            return 'moderate'
        else:
            return 'limited'
    
    def _calculate_avg_email_importance(self, email: Email) -> float:
        """Calculate average email importance"""
        if hasattr(email, 'strategic_importance') and email.strategic_importance:
            return email.strategic_importance
        
        # Fallback calculation
        if self._is_strategic_communication(email):
            return 0.8
        else:
            return 0.5
    
    def _assess_relationship_trend(self, existing_person) -> str:
        """Assess relationship trend"""
        if not existing_person:
            return 'new'
        
        # Simple trend assessment
        if existing_person.total_emails and existing_person.total_emails >= 10:
            return 'stable'
        elif existing_person.total_emails and existing_person.total_emails >= 3:
            return 'growing'
        else:
            return 'developing'
    
    def _assess_engagement_level(self, email: Email, sender_analysis: Dict) -> str:
        """Assess engagement level"""
        # High engagement indicators
        if self._is_strategic_communication(email):
            return 'high'
        elif sender_analysis.get('company') and sender_analysis.get('role'):
            return 'medium'
        else:
            return 'standard'
    
    def _assess_communication_consistency(self, existing_person) -> str:
        """Assess communication consistency"""
        if not existing_person:
            return 'new'
        
        if existing_person.total_emails and existing_person.total_emails >= 15:
            return 'consistent'
        elif existing_person.total_emails and existing_person.total_emails >= 5:
            return 'regular'
        else:
            return 'sporadic'
    
    def _calculate_business_value_score(self, sender_analysis: Dict, email: Email) -> float:
        """Calculate business value score"""
        value = 0.3  # Base value
        
        # Strategic communication adds value
        if self._is_strategic_communication(email):
            value += 0.4
        
        # Company affiliation adds value
        if sender_analysis.get('company'):
            value += 0.2
        
        # Role authority adds value
        role = sender_analysis.get('role', '').lower()
        if any(keyword in role for keyword in ['director', 'manager', 'ceo', 'vp']):
            value += 0.3
        
        return min(1.0, value)
    
    def _calculate_collaboration_strength(self, email: Email, analysis: Dict) -> float:
        """Calculate collaboration strength"""
        strength = 0.2  # Base strength
        
        # Project involvement
        if analysis.get('project'):
            strength += 0.5
        
        # Meeting coordination
        if self._is_meeting_participant(email):
            strength += 0.3
        
        return min(1.0, strength)
    
    def _assess_decision_influence(self, analysis: Dict, email: Email) -> float:
        """Assess decision influence"""
        influence = 0.3  # Base influence
        
        # Key decisions mentioned
        business_insights = analysis.get('business_insights', {})
        if isinstance(business_insights, dict) and business_insights.get('key_decisions'):
            influence += 0.4
        
        # Strategic communication
        if self._is_strategic_communication(email):
            influence += 0.3
        
        return min(1.0, influence)
    
    def _assess_urgency_compatibility(self, email: Email) -> str:
        """Assess urgency compatibility"""
        urgency = self._assess_email_urgency(email)
        
        if urgency > 0.7:
            return 'high-urgency'
        elif urgency > 0.4:
            return 'moderate-urgency'
        else:
            return 'low-urgency'
    
    def _has_action_required(self, email: Email) -> bool:
        """Check if email has action required"""
        if hasattr(email, 'action_required') and email.action_required:
            return True
        
        # Fallback analysis
        if email.subject:
            action_keywords = ['please', 'need', 'require', 'action', 'respond', 'reply', 'confirm']
            return any(keyword in email.subject.lower() for keyword in action_keywords)
        
        return False

# Global instance
email_intelligence = EmailIntelligenceProcessor() 


================================================================================
FILE: chief_of_staff_ai/processors/email_quality_filter.py
PURPOSE: Contact tier classification system (Tier 1 = sent emails)
================================================================================
"""
ðŸŽ¯ Email Quality Filter - Intelligent Email Injection System
==========================================================

This module implements a sophisticated email quality filtering system based on user engagement patterns.
The system categorizes contacts into tiers and filters email injection accordingly.

TIER SYSTEM:
- Tier 1: People you respond to regularly (HIGH QUALITY - Always process)
- Tier 2: New contacts or occasional contacts (MEDIUM QUALITY - Process with caution)
- Tier LAST: Contacts you never respond to (LOW QUALITY - Ignore completely)

Author: AI Chief of Staff
Created: December 2024
"""

import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Set, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum
import json
import re
from collections import defaultdict, Counter
from email.utils import parseaddr

from models.database import get_db_manager
from models.enhanced_models import Email, Person, Task
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_, desc, func

logger = logging.getLogger(__name__)

class ContactTier(Enum):
    """Contact tier classifications based on engagement patterns"""
    TIER_1 = "tier_1"           # High engagement - always respond to
    TIER_2 = "tier_2"           # Medium engagement - new or occasional 
    TIER_LAST = "tier_last"     # No engagement - consistently ignore
    UNCLASSIFIED = "unclassified"  # Not yet analyzed

@dataclass
class ContactEngagementStats:
    """Statistics for contact engagement analysis"""
    email_address: str
    name: Optional[str]
    emails_received: int
    emails_responded_to: int
    last_email_date: datetime
    first_email_date: datetime
    response_rate: float
    days_since_last_email: int
    avg_days_between_emails: float
    tier: ContactTier
    tier_reason: str
    should_process: bool

@dataclass
class EmailQualityResult:
    """Result of email quality assessment"""
    should_process: bool
    tier: ContactTier
    reason: str
    sender_stats: Optional[ContactEngagementStats]
    confidence: float

class EmailQualityFilter:
    """
    Intelligent email quality filtering system that categorizes contacts
    based on engagement patterns and filters email injection accordingly.
    """
    
    def __init__(self):
        """Initialize the EmailQualityFilter with configuration"""
        from models.database import get_db_manager
        
        self.db_manager = get_db_manager()
        self._contact_tiers: Dict[str, ContactEngagementStats] = {}
        self._last_tier_update: Optional[datetime] = None
        
        # Configuration for tier classification thresholds
        self.TIER_1_MIN_RESPONSE_RATE = 0.5  # 50% response rate for Tier 1
        self.TIER_LAST_MAX_RESPONSE_RATE = 0.1  # 10% max for Tier LAST
        self.TIER_LAST_MIN_EMAILS = 5  # Need at least 5 emails to classify as Tier LAST
        self.MIN_EMAILS_FOR_CLASSIFICATION = 3  # Minimum emails needed for tier classification
        self.NEW_CONTACT_GRACE_PERIOD = 30  # Days to give new contacts grace period
        self.MONTHLY_REVIEW_DAYS = 30  # Review tiers every 30 days
        
        # Clear any corrupted cache data on startup
        self.clear_corrupted_cache()
        
    def analyze_email_quality(self, email_data: Dict, user_id: int) -> EmailQualityResult:
        """
        Main entry point: Analyze if an email should be processed based on sender quality.
        
        Args:
            email_data: Email data dictionary with sender, subject, body, etc.
            user_id: User ID for analysis
            
        Returns:
            EmailQualityResult with processing decision and reasoning
        """
        try:
            sender_email = self._extract_sender_email(email_data)
            if not sender_email:
                return EmailQualityResult(
                    should_process=False,
                    tier=ContactTier.UNCLASSIFIED,
                    reason="No valid sender email found",
                    sender_stats=None,
                    confidence=1.0
                )
            
            # Check if we need to update contact tiers
            if self._should_refresh_tiers():
                logger.info(f"ðŸ”„ Refreshing contact tiers for user {user_id}")
                self._analyze_all_contacts(user_id)
            
            # Get sender engagement stats
            sender_stats = self._get_contact_stats(sender_email, user_id)
            
            # Make processing decision based on tier
            should_process, reason, confidence = self._make_processing_decision(sender_stats, email_data)
            
            logger.info(f"ðŸ“§ Email quality check: {sender_email} -> {sender_stats.tier.value} -> {'PROCESS' if should_process else 'SKIP'}")
            
            return EmailQualityResult(
                should_process=should_process,
                tier=sender_stats.tier,
                reason=reason,
                sender_stats=sender_stats,
                confidence=confidence
            )
            
        except Exception as e:
            logger.error(f"âŒ Email quality analysis error: {str(e)}")
            # Fail open - process email if analysis fails
            return EmailQualityResult(
                should_process=True,
                tier=ContactTier.UNCLASSIFIED,
                reason=f"Analysis error: {str(e)}",
                sender_stats=None,
                confidence=0.0
            )
    
    def _extract_sender_email(self, email_data: Dict) -> Optional[str]:
        """Extract and normalize sender email address"""
        sender = email_data.get('sender') or email_data.get('from') or email_data.get('From')
        if not sender:
            return None
        
        # Extract email from various formats: "Name <email@domain.com>" or "email@domain.com"
        email_match = re.search(r'[\w\.-]+@[\w\.-]+\.\w+', sender)
        if email_match:
            return email_match.group(0).lower().strip()
        
        return None
    
    def _should_refresh_tiers(self) -> bool:
        """Check if contact tiers need to be refreshed"""
        if not self._last_tier_update:
            return True
        
        days_since_update = (datetime.now() - self._last_tier_update).days
        return days_since_update >= self.MONTHLY_REVIEW_DAYS
    
    def _analyze_all_contacts(self, user_id: int):
        """
        Comprehensive analysis of all contacts to determine tiers.
        This is the core intelligence that implements your engagement-based tiering.
        """
        logger.info(f"ðŸ§  Running comprehensive contact tier analysis for user {user_id}")
        
        with self.db_manager.get_session() as session:
            # Get all emails for analysis
            all_emails = session.query(Email).filter(Email.user_id == user_id).all()
            
            # Get user's sent emails to identify who they respond to
            sent_emails = [email for email in all_emails if self._is_sent_email(email)]
            received_emails = [email for email in all_emails if not self._is_sent_email(email)]
            
            logger.info(f"ðŸ“Š Analyzing {len(received_emails)} received emails and {len(sent_emails)} sent emails")
            
            # Build engagement statistics
            contact_stats = self._build_engagement_statistics(received_emails, sent_emails)
            
            # Classify contacts into tiers
            self._classify_contacts_into_tiers(contact_stats)
            
            # Cache results
            self._contact_tiers = {stats.email_address: stats for stats in contact_stats.values()}
            self._last_tier_update = datetime.now()
            
            # Log tier summary
            self._log_tier_summary(contact_stats)
    
    def _is_sent_email(self, email: Email) -> bool:
        """Determine if an email was sent by the user"""
        # Heuristics to identify sent emails
        if hasattr(email, 'is_sent') and email.is_sent:
            return True
        
        # Check common sent folder indicators
        if hasattr(email, 'folder') and email.folder:
            sent_indicators = ['sent', 'outbox', 'drafts']
            return any(indicator in email.folder.lower() for indicator in sent_indicators)
        
        # Check subject for "Re:" or "Fwd:" patterns and check if it's a response
        if hasattr(email, 'subject') and email.subject:
            # This is a simplified heuristic - in real implementation you'd want more sophisticated detection
            return False
        
        return False
    
    def _build_engagement_statistics(self, received_emails: List[Email], sent_emails: List[Email]) -> Dict[str, ContactEngagementStats]:
        """Build comprehensive engagement statistics for all contacts"""
        contact_stats = {}
        
        # Group received emails by sender
        emails_by_sender = defaultdict(list)
        for email in received_emails:
            sender = self._extract_sender_email({'sender': email.sender})
            if sender:
                emails_by_sender[sender].append(email)
        
        # Build sent email lookup for response detection
        sent_subjects = set()
        sent_recipients = set()
        for email in sent_emails:
            if hasattr(email, 'recipient_emails') and email.recipient_emails:
                # Extract recipients from sent emails
                recipients = self._extract_email_addresses(email.recipient_emails)
                sent_recipients.update(recipients)
            
            if hasattr(email, 'subject') and email.subject:
                sent_subjects.add(email.subject.lower().strip())
        
        # Analyze each contact
        for sender_email, sender_emails in emails_by_sender.items():
            if len(sender_emails) == 0:
                continue
            
            # Calculate basic stats
            emails_received = len(sender_emails)
            first_email_date = min(email.email_date for email in sender_emails if email.email_date)
            last_email_date = max(email.email_date for email in sender_emails if email.email_date)
            
            # Calculate response rate (sophisticated heuristic)
            emails_responded_to = self._calculate_response_count(sender_emails, sent_subjects, sent_recipients, sender_email)
            response_rate = emails_responded_to / emails_received if emails_received > 0 else 0.0
            
            # Calculate timing statistics
            days_since_last = (datetime.now() - last_email_date).days if last_email_date else 999
            total_days = (last_email_date - first_email_date).days if first_email_date and last_email_date else 1
            avg_days_between = total_days / max(1, emails_received - 1) if emails_received > 1 else 0
            
            # Get contact name
            contact_name = sender_emails[0].sender_name if hasattr(sender_emails[0], 'sender_name') else None
            
            stats = ContactEngagementStats(
                email_address=sender_email,
                name=contact_name,
                emails_received=emails_received,
                emails_responded_to=emails_responded_to,
                last_email_date=last_email_date,
                first_email_date=first_email_date,
                response_rate=response_rate,
                days_since_last_email=days_since_last,
                avg_days_between_emails=avg_days_between,
                tier=ContactTier.UNCLASSIFIED,  # Will be set in classification step
                tier_reason="",
                should_process=True
            )
            
            contact_stats[sender_email] = stats
        
        return contact_stats
    
    def _extract_email_addresses(self, recipients_string: str) -> List[str]:
        """Extract email addresses from recipients string"""
        if not recipients_string:
            return []
        
        emails = re.findall(r'[\w\.-]+@[\w\.-]+\.\w+', recipients_string)
        return [email.lower().strip() for email in emails]
    
    def _calculate_response_count(self, sender_emails: List[Email], sent_subjects: Set[str], sent_recipients: Set[str], sender_email: str) -> int:
        """
        Calculate how many emails from this sender we responded to.
        Uses sophisticated heuristics to detect responses.
        """
        responses = 0
        
        # Check if we ever sent emails to this sender
        if sender_email in sent_recipients:
            responses += 1  # Basic engagement indicator
        
        # Check for subject-based response patterns
        for email in sender_emails:
            if not email.subject:
                continue
            
            subject = email.subject.lower().strip()
            
            # Look for response patterns in sent emails
            response_patterns = [
                f"re: {subject}",
                f"re:{subject}",
                subject  # Exact match might indicate a response
            ]
            
            for pattern in response_patterns:
                if pattern in sent_subjects:
                    responses += 1
                    break
        
        return min(responses, len(sender_emails))  # Cap at number of emails received
    
    def _classify_contacts_into_tiers(self, contact_stats: Dict[str, ContactEngagementStats]):
        """
        Classify contacts into tiers based on engagement patterns.
        This implements your core tiering logic.
        """
        for email_address, stats in contact_stats.items():
            tier, reason, should_process = self._determine_contact_tier(stats)
            
            stats.tier = tier
            stats.tier_reason = reason
            stats.should_process = should_process
    
    def _determine_contact_tier(self, stats: ContactEngagementStats) -> Tuple[ContactTier, str, bool]:
        """
        Core logic to determine contact tier based on engagement statistics.
        Implements your specified tiering rules.
        """
        # Get user's email addresses
        from models.database import get_db_manager
        user = get_db_manager().get_user_by_email(stats.email_address)
        
        # If this is one of the user's own email addresses, always Tier 1
        if user:
            return ContactTier.TIER_1, "User's own email address", True
            
        # Check for common variations of the user's email
        if user and stats.email_address.split('@')[0] in ['sandman', 'oudi', 'oudiantebi']:
            return ContactTier.TIER_1, "User's alias email address", True
        
        # NEW: Check if this contact is from sent emails (TrustedContact) - these are automatically Tier 1
        try:
            with get_db_manager().get_session() as session:
                from models.database import TrustedContact
                trusted_contact = session.query(TrustedContact).filter(
                    TrustedContact.email_address == stats.email_address
                ).first()
                
                if trusted_contact:
                    return ContactTier.TIER_1, f"Contact from sent emails (engagement: {trusted_contact.engagement_score:.1f})", True
        except Exception as e:
            logger.warning(f"Could not check TrustedContact for {stats.email_address}: {e}")
        
        # Tier 1: People you respond to regularly (HIGH QUALITY)
        if stats.response_rate >= self.TIER_1_MIN_RESPONSE_RATE:
            return ContactTier.TIER_1, f"High response rate ({stats.response_rate:.1%})", True
        
        # Tier LAST: People you consistently ignore (LOW QUALITY)
        if (stats.emails_received >= self.TIER_LAST_MIN_EMAILS and 
            stats.response_rate <= self.TIER_LAST_MAX_RESPONSE_RATE and
            stats.days_since_last_email <= 60):  # Still actively emailing
            return ContactTier.TIER_LAST, f"Low response rate ({stats.response_rate:.1%}) with {stats.emails_received} emails", False
        
        # New contacts (grace period)
        if stats.days_since_last_email <= self.NEW_CONTACT_GRACE_PERIOD:
            return ContactTier.TIER_2, "New contact (grace period)", True
        
        # Insufficient data for classification
        if stats.emails_received < self.MIN_EMAILS_FOR_CLASSIFICATION:
            return ContactTier.TIER_2, f"Insufficient data ({stats.emails_received} emails)", True
        
        # Default to Tier 2 (MEDIUM QUALITY)
        return ContactTier.TIER_2, f"Medium engagement ({stats.response_rate:.1%})", True
    
    def _log_tier_summary(self, contact_stats: Dict[str, ContactEngagementStats]):
        """Log summary of tier classification results"""
        tier_counts = Counter(stats.tier for stats in contact_stats.values())
        
        logger.info("ðŸ“Š Contact Tier Classification Summary:")
        logger.info(f"   ðŸ‘‘ Tier 1 (High Quality): {tier_counts[ContactTier.TIER_1]} contacts")
        logger.info(f"   âš–ï¸  Tier 2 (Medium Quality): {tier_counts[ContactTier.TIER_2]} contacts")
        logger.info(f"   ðŸ—‘ï¸  Tier LAST (Low Quality): {tier_counts[ContactTier.TIER_LAST]} contacts")
        logger.info(f"   â“ Unclassified: {tier_counts[ContactTier.UNCLASSIFIED]} contacts")
        
        # Log some examples
        tier_1_examples = [stats.email_address for stats in contact_stats.values() if stats.tier == ContactTier.TIER_1][:3]
        tier_last_examples = [stats.email_address for stats in contact_stats.values() if stats.tier == ContactTier.TIER_LAST][:3]
        
        if tier_1_examples:
            logger.info(f"   ðŸ‘‘ Tier 1 examples: {', '.join(tier_1_examples)}")
        if tier_last_examples:
            logger.info(f"   ðŸ—‘ï¸  Tier LAST examples: {', '.join(tier_last_examples)}")
    
    def _get_contact_stats(self, sender_email: str, user_id: int) -> ContactEngagementStats:
        """Get cached contact statistics or analyze on-demand"""
        
        # Return cached stats if available
        if sender_email in self._contact_tiers:
            return self._contact_tiers[sender_email]
        
        # Analyze this specific contact on-demand
        logger.info(f"ðŸ” On-demand analysis for new contact: {sender_email}")
        
        with self.db_manager.get_session() as session:
            # Get emails from this sender
            sender_emails = session.query(Email).filter(
                and_(Email.user_id == user_id, Email.sender.ilike(f"%{sender_email}%"))
            ).all()
            
            if not sender_emails:
                # New contact - no history
                stats = ContactEngagementStats(
                    email_address=sender_email,
                    name=None,
                    emails_received=0,
                    emails_responded_to=0,
                    last_email_date=datetime.now(),
                    first_email_date=datetime.now(),
                    response_rate=0.0,
                    days_since_last_email=0,
                    avg_days_between_emails=0.0,
                    tier=ContactTier.TIER_2,
                    tier_reason="New contact",
                    should_process=True
                )
            else:
                # Quick analysis for this contact
                stats = self._quick_contact_analysis(sender_emails, sender_email, user_id)
            
            # Cache the result
            self._contact_tiers[sender_email] = stats
            return stats
    
    def _quick_contact_analysis(self, sender_emails: List[Email], sender_email: str, user_id: int) -> ContactEngagementStats:
        """Perform quick analysis for a single contact"""
        
        emails_received = len(sender_emails)
        first_email_date = min(email.email_date for email in sender_emails if email.email_date)
        last_email_date = max(email.email_date for email in sender_emails if email.email_date)
        
        # Quick response rate estimation (simplified)
        with self.db_manager.get_session() as session:
            sent_to_sender = session.query(Email).filter(
                and_(
                    Email.user_id == user_id,
                    Email.recipient_emails.ilike(f"%{sender_email}%")
                )
            ).count()
        
        response_rate = min(1.0, sent_to_sender / emails_received) if emails_received > 0 else 0.0
        
        days_since_last = (datetime.now() - last_email_date).days if last_email_date else 0
        
        stats = ContactEngagementStats(
            email_address=sender_email,
            name=sender_emails[0].sender_name if hasattr(sender_emails[0], 'sender_name') else None,
            emails_received=emails_received,
            emails_responded_to=sent_to_sender,
            last_email_date=last_email_date,
            first_email_date=first_email_date,
            response_rate=response_rate,
            days_since_last_email=days_since_last,
            avg_days_between_emails=0.0,
            tier=ContactTier.UNCLASSIFIED,
            tier_reason="Quick analysis",
            should_process=True
        )
        
        tier, reason, should_process = self._determine_contact_tier(stats)
        stats.tier = tier
        stats.tier_reason = reason
        stats.should_process = should_process
        
        return stats
    
    def _make_processing_decision(self, sender_stats: ContactEngagementStats, email_data: Dict) -> Tuple[bool, str, float]:
        """
        Make the final decision on whether to process this email based on sender tier
        and additional email characteristics.
        """
        
        # Base decision on sender tier
        base_decision = sender_stats.should_process
        base_reason = f"Sender tier: {sender_stats.tier.value} - {sender_stats.tier_reason}"
        
        # Additional quality checks
        confidence = 0.8
        
        # Check for obvious spam/promotional indicators
        subject = email_data.get('subject', '').lower()
        spam_indicators = ['unsubscribe', 'marketing', 'promotion', 'sale', 'deal', 'offer', '% off']
        
        if any(indicator in subject for indicator in spam_indicators):
            if sender_stats.tier != ContactTier.TIER_1:  # Don't filter Tier 1 contacts
                return False, f"{base_reason} + Spam indicators detected", 0.9
        
        # Check for very short or empty content
        body = email_data.get('body', '') or email_data.get('body_text', '')
        if len(body.strip()) < 50 and sender_stats.tier == ContactTier.TIER_LAST:
            return False, f"{base_reason} + Low content quality", 0.85
        
        return base_decision, base_reason, confidence
    
    def force_tier_refresh(self, user_id: int):
        """Force a refresh of contact tiers (useful for manual testing)"""
        logger.info(f"ðŸ”„ Forcing contact tier refresh for user {user_id}")
        self._contact_tiers.clear()
        self._last_tier_update = None
        self._analyze_all_contacts(user_id)

    def clear_corrupted_cache(self):
        """Clear any corrupted cache data and reinitialize"""
        logger.info("ðŸ§¹ Clearing potentially corrupted contact tier cache")
        
        # Check for corrupted objects in cache
        corrupted_keys = []
        for email_address, obj in self._contact_tiers.items():
            if not isinstance(obj, ContactEngagementStats):
                logger.warning(f"âŒ Found corrupted object in cache: {email_address} -> {type(obj)}")
                corrupted_keys.append(email_address)
        
        # Remove corrupted entries
        for key in corrupted_keys:
            del self._contact_tiers[key]
        
        if corrupted_keys:
            logger.info(f"ðŸ§¹ Removed {len(corrupted_keys)} corrupted cache entries")
        
        # Reset timestamps to force fresh analysis
        self._last_tier_update = None
    
    def get_contact_tier_summary(self, user_id: int) -> Dict:
        """Get a summary of contact tiers for reporting/debugging"""
        if not self._contact_tiers:
            self._analyze_all_contacts(user_id)
        
        tier_summary = {
            'total_contacts': len(self._contact_tiers),
            'last_updated': self._last_tier_update.isoformat() if self._last_tier_update else None,
            'tier_counts': {},
            'examples': {}
        }
        
        # Count by tier
        for tier in ContactTier:
            contacts_in_tier = [stats for stats in self._contact_tiers.values() if stats.tier == tier]
            tier_summary['tier_counts'][tier.value] = len(contacts_in_tier)
            
            # Add examples
            examples = [stats.email_address for stats in contacts_in_tier[:5]]
            tier_summary['examples'][tier.value] = examples
        
        return tier_summary
    
    def override_contact_tier(self, email_address: str, new_tier: ContactTier, reason: str = "Manual override"):
        """Allow manual override of contact tier (for edge cases)"""
        email_address = email_address.lower().strip()
        
        if email_address in self._contact_tiers:
            # Safety check: ensure we have a ContactEngagementStats object
            contact_stats = self._contact_tiers[email_address]
            if not isinstance(contact_stats, ContactEngagementStats):
                logger.error(f"âŒ Invalid object type in contact tiers: {type(contact_stats)} for {email_address}")
                # Create a proper ContactEngagementStats object
                contact_stats = ContactEngagementStats(
                    email_address=email_address,
                    name=None,
                    emails_received=0,
                    emails_responded_to=0,
                    last_email_date=datetime.now(),
                    first_email_date=datetime.now(),
                    response_rate=0.0,
                    days_since_last_email=0,
                    avg_days_between_emails=0.0,
                    tier=new_tier,
                    tier_reason=reason,
                    should_process=new_tier != ContactTier.TIER_LAST
                )
                self._contact_tiers[email_address] = contact_stats
            else:
                old_tier = contact_stats.tier
                contact_stats.tier = new_tier
                contact_stats.tier_reason = reason
                contact_stats.should_process = new_tier != ContactTier.TIER_LAST
                
                logger.info(f"âœï¸  Manual tier override: {email_address} {old_tier.value} -> {new_tier.value}")
        else:
            # Create new contact stats for unknown contact
            contact_stats = ContactEngagementStats(
                email_address=email_address,
                name=None,
                emails_received=0,
                emails_responded_to=0,
                last_email_date=datetime.now(),
                first_email_date=datetime.now(),
                response_rate=0.0,
                days_since_last_email=0,
                avg_days_between_emails=0.0,
                tier=new_tier,
                tier_reason=reason,
                should_process=new_tier != ContactTier.TIER_LAST
            )
            self._contact_tiers[email_address] = contact_stats
            logger.info(f"âœï¸  Created new contact with tier: {email_address} -> {new_tier.value}")

    def cleanup_existing_low_quality_data(self, user_id: int) -> Dict[str, Any]:
        """
        Clean up existing database records that came from Tier LAST contacts.
        This removes emails, tasks, and insights generated from low-quality contacts.
        
        Args:
            user_id: User ID to clean up data for
            
        Returns:
            Dictionary with cleanup statistics
        """
        try:
            from models.database import get_db_manager, Email, Task, Person
            
            logger.info(f"ðŸ§¹ Starting cleanup of low-quality data for user {user_id}")
            
            # Get contact tier summary to identify Tier LAST contacts
            tier_summary = self.get_contact_tier_summary(user_id)
            
            cleanup_stats = {
                'emails_removed': 0,
                'tasks_removed': 0,
                'people_removed': 0,
                'insights_cleaned': 0,
                'tier_last_contacts': 0
            }
            
            with get_db_manager().get_session() as session:
                # Get all people for this user
                all_people = session.query(Person).filter(Person.user_id == user_id).all()
                
                tier_last_emails = set()
                tier_last_people_ids = []
                
                for person in all_people:
                    if person.email_address:
                        contact_stats = self._get_contact_stats(person.email_address.lower(), user_id)
                        
                        if contact_stats.tier == ContactTier.TIER_LAST:
                            tier_last_emails.add(person.email_address.lower())
                            tier_last_people_ids.append(person.id)
                            cleanup_stats['tier_last_contacts'] += 1
                
                logger.info(f"ðŸ—‘ï¸  Found {len(tier_last_emails)} Tier LAST contacts to clean up")
                
                # Remove emails from Tier LAST contacts
                if tier_last_emails:
                    emails_to_remove = session.query(Email).filter(
                        Email.user_id == user_id,
                        Email.sender.ilike_any([f"%{email}%" for email in tier_last_emails])
                    ).all()
                    
                    for email in emails_to_remove:
                        session.delete(email)
                        cleanup_stats['emails_removed'] += 1
                
                # Remove tasks that might have been generated from these emails
                # This is approximate - we can't definitively trace task origin
                if tier_last_people_ids:
                    # Remove tasks that mention these people in description
                    all_tasks = session.query(Task).filter(Task.user_id == user_id).all()
                    
                    for task in all_tasks:
                        if task.description:
                            # Check if task mentions any Tier LAST contact
                            task_desc_lower = task.description.lower()
                            for person_id in tier_last_people_ids:
                                person = session.query(Person).get(person_id)
                                if person and person.name:
                                    if person.name.lower() in task_desc_lower:
                                        session.delete(task)
                                        cleanup_stats['tasks_removed'] += 1
                                        break
                
                # Optionally remove Tier LAST people entirely (uncomment if desired)
                # for person_id in tier_last_people_ids:
                #     person = session.query(Person).get(person_id)
                #     if person:
                #         session.delete(person)
                #         cleanup_stats['people_removed'] += 1
                
                session.commit()
                
            logger.info(f"âœ… Cleanup complete: {cleanup_stats}")
            
            return {
                'success': True,
                'cleanup_stats': cleanup_stats,
                'message': f"Cleaned up {cleanup_stats['emails_removed']} emails and {cleanup_stats['tasks_removed']} tasks from {cleanup_stats['tier_last_contacts']} Tier LAST contacts"
            }
            
        except Exception as e:
            logger.error(f"âŒ Cleanup error: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }

    def set_all_contacts_tier_1(self, user_email: str):
        """Set all contacts from sent emails to Tier 1"""
        from models.database import get_db_manager
        
        try:
            # Get user from database
            db_user = get_db_manager().get_user_by_email(user_email)
            if not db_user:
                logger.error(f"User {user_email} not found")
                return False
            
            # Get all sent emails
            with get_db_manager().get_session() as session:
                sent_emails = session.query(Email).filter(
                    Email.user_id == db_user.id,
                    Email.sender.ilike(f'%{user_email}%')  # Emails sent by the user
                ).all()
                
                # Extract all unique recipients
                recipients = set()
                for email in sent_emails:
                    # Add the user's own email addresses
                    if email.sender:
                        sender_email = parseaddr(email.sender)[1].lower()
                        if sender_email and '@' in sender_email:
                            recipients.add(sender_email)
                    
                    # Add recipients
                    if email.recipient_emails:
                        if isinstance(email.recipient_emails, str):
                            try:
                                recipient_list = json.loads(email.recipient_emails)
                            except:
                                recipient_list = [email.recipient_emails]
                        else:
                            recipient_list = email.recipient_emails
                            
                        for recipient in recipient_list:
                            email_addr = parseaddr(recipient)[1].lower()
                            if email_addr and '@' in email_addr:
                                recipients.add(email_addr)
                
                # Set all recipients to Tier 1 with proper stats
                for recipient in recipients:
                    stats = ContactEngagementStats(
                        email_address=recipient,
                        name=None,  # We don't have the name here
                        emails_received=1,  # Placeholder value
                        emails_responded_to=1,  # Assume responded since it's from sent emails
                        last_email_date=datetime.now(timezone.utc),
                        first_email_date=datetime.now(timezone.utc),
                        response_rate=1.0,  # Perfect response rate for Tier 1
                        days_since_last_email=0,
                        avg_days_between_emails=0,
                        tier=ContactTier.TIER_1,
                        tier_reason="Sent email contact",
                        should_process=True
                    )
                    self._contact_tiers[recipient] = stats
                
                logger.info(f"âœ… Set {len(recipients)} contacts to Tier 1 for {user_email}")
                return True
                
        except Exception as e:
            logger.error(f"Failed to set contacts to Tier 1: {str(e)}")
            return False

# Global instance
email_quality_filter = EmailQualityFilter()

def analyze_email_quality(email_data: Dict, user_id: int) -> EmailQualityResult:
    """
    Convenience function for email quality analysis.
    
    Usage:
        result = analyze_email_quality(email_data, user_id)
        if result.should_process:
            # Process the email
            pass
    """
    return email_quality_filter.analyze_email_quality(email_data, user_id)

def force_refresh_contact_tiers(user_id: int):
    """Force refresh of contact tiers (useful for monthly review)"""
    email_quality_filter.force_tier_refresh(user_id)

def get_contact_tier_summary(user_id: int) -> Dict:
    """Get summary of contact tiers for debugging/monitoring"""
    return email_quality_filter.get_contact_tier_summary(user_id) 


================================================================================
FILE: chief_of_staff_ai/processors/enhanced_processors/enhanced_data_normalizer.py
PURPOSE: Email processor: Enhanced Data Normalizer
================================================================================
# Enhanced Data Normalizer - Stub Implementation
import logging
from typing import Dict, Any
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class NormalizationResult:
    success: bool = True
    normalized_data: Dict = None
    quality_score: float = 0.8
    issues_found: list = None
    processing_notes: list = None

class EnhancedDataNormalizer:
    """Stub implementation of enhanced data normalizer"""
    
    def normalize_email_data(self, email_data: Dict) -> NormalizationResult:
        """Normalize email data"""
        try:
            # Basic normalization - just pass through the data
            return NormalizationResult(
                success=True,
                normalized_data=email_data,
                quality_score=0.8,
                issues_found=[],
                processing_notes=["Stub normalizer - basic pass-through"]
            )
        except Exception as e:
            logger.error(f"Error in email normalization: {str(e)}")
            return NormalizationResult(
                success=False,
                normalized_data={},
                quality_score=0.0,
                issues_found=[str(e)],
                processing_notes=[]
            )
    
    def normalize_calendar_data(self, calendar_data: Dict) -> NormalizationResult:
        """Normalize calendar data"""
        try:
            # Basic normalization - just pass through the data
            return NormalizationResult(
                success=True,
                normalized_data=calendar_data,
                quality_score=0.8,
                issues_found=[],
                processing_notes=["Stub normalizer - basic pass-through"]
            )
        except Exception as e:
            logger.error(f"Error in calendar normalization: {str(e)}")
            return NormalizationResult(
                success=False,
                normalized_data={},
                quality_score=0.0,
                issues_found=[str(e)],
                processing_notes=[]
            )

# Global instance
enhanced_data_normalizer = EnhancedDataNormalizer() 


================================================================================
FILE: chief_of_staff_ai/processors/enhanced_processors/__init__.py
PURPOSE: Email processor:   Init  
================================================================================
# Enhanced Processors Package 


================================================================================
FILE: chief_of_staff_ai/processors/enhanced_processors/enhanced_email_processor.py
PURPOSE: Email processor: Enhanced Email Processor
================================================================================
# Enhanced Email Processor - Entity-Centric Email Intelligence
# This replaces the old email_intelligence.py with unified entity engine integration

import logging
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
import json
import re

from processors.unified_entity_engine import entity_engine, EntityContext
from processors.enhanced_ai_pipeline import enhanced_ai_processor
from processors.realtime_processor import realtime_processor
from models.enhanced_models import Email, Person, Topic, Task, CalendarEvent

logger = logging.getLogger(__name__)

class EnhancedEmailProcessor:
    """
    Enhanced email processor that leverages the unified entity engine and real-time processing.
    This replaces the old email_intelligence.py with context-aware, entity-integrated email analysis.
    """
    
    def __init__(self):
        self.entity_engine = entity_engine
        self.ai_processor = enhanced_ai_processor
        self.realtime_processor = realtime_processor
        
    # =====================================================================
    # MAIN EMAIL PROCESSING METHODS
    # =====================================================================
    
    def process_email_comprehensive(self, email_data: Dict, user_id: int, 
                                   real_time: bool = True) -> Dict[str, Any]:
        """
        Comprehensive email processing with entity creation and relationship building.
        This is the main entry point that replaces old email processing.
        """
        try:
            logger.info(f"Processing email comprehensively for user {user_id}")
            
            # Step 1: Normalize email data
            normalized_email = self._normalize_email_data(email_data)
            
            # Step 2: Check for duplicates
            if self._is_duplicate_email(normalized_email, user_id):
                logger.info(f"Duplicate email detected, skipping processing")
                return {'success': True, 'result': {'status': 'duplicate', 'processed': False}}
            
            # Step 3: Use enhanced AI pipeline for comprehensive processing
            if real_time:
                # Queue for real-time processing
                self.realtime_processor.process_new_email(normalized_email, user_id, priority=5)
                
                return {
                    'success': True, 
                    'result': {
                        'status': 'queued_for_realtime',
                        'processed': True,
                        'message': 'Email queued for real-time intelligence processing'
                    }
                }
            else:
                # Process immediately
                result = self.ai_processor.process_email_with_context(normalized_email, user_id)
                
                if result.success:
                    # Extract comprehensive processing summary
                    summary = {
                        'email_id': normalized_email.get('gmail_id'),
                        'processing_summary': {
                            'entities_created': result.entities_created,
                            'entities_updated': result.entities_updated,
                            'processing_time': result.processing_time,
                            'insights_generated': len(result.insights_generated)
                        },
                        'intelligence_summary': self._create_intelligence_summary(result, normalized_email),
                        'entity_relationships': self._extract_entity_relationships(result),
                        'action_items': self._extract_action_items(result),
                        'strategic_insights': result.insights_generated
                    }
                    
                    logger.info(f"Successfully processed email: {summary['processing_summary']}")
                    return {'success': True, 'result': summary}
                else:
                    logger.error(f"Failed to process email: {result.error}")
                    return {'success': False, 'error': result.error}
                    
        except Exception as e:
            logger.error(f"Error in comprehensive email processing: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def process_email_batch(self, email_list: List[Dict], user_id: int, 
                           batch_size: int = 10) -> Dict[str, Any]:
        """
        Process multiple emails in batches with efficiency optimizations.
        """
        try:
            logger.info(f"Processing batch of {len(email_list)} emails for user {user_id}")
            
            # Get user context once for the entire batch
            user_context = self.ai_processor._gather_user_context(user_id)
            
            results = {
                'total_emails': len(email_list),
                'processed': 0,
                'failed': 0,
                'duplicates': 0,
                'batch_summary': {
                    'total_entities_created': {'people': 0, 'topics': 0, 'tasks': 0, 'projects': 0},
                    'total_insights': 0,
                    'processing_time': 0.0
                },
                'individual_results': []
            }
            
            # Process in batches
            for i in range(0, len(email_list), batch_size):
                batch = email_list[i:i + batch_size]
                batch_results = self._process_email_batch_chunk(batch, user_id, user_context)
                
                # Aggregate results
                for result in batch_results:
                    results['individual_results'].append(result)
                    
                    if result['success']:
                        if result['result'].get('status') == 'duplicate':
                            results['duplicates'] += 1
                        else:
                            results['processed'] += 1
                            # Aggregate batch summary
                            processing_summary = result['result'].get('processing_summary', {})
                            entities_created = processing_summary.get('entities_created', {})
                            
                            for entity_type, count in entities_created.items():
                                results['batch_summary']['total_entities_created'][entity_type] += count
                                
                            results['batch_summary']['total_insights'] += processing_summary.get('insights_generated', 0)
                            results['batch_summary']['processing_time'] += processing_summary.get('processing_time', 0)
                    else:
                        results['failed'] += 1
            
            logger.info(f"Batch processing complete: {results['processed']} processed, "
                       f"{results['failed']} failed, {results['duplicates']} duplicates")
            
            return {'success': True, 'result': results}
            
        except Exception as e:
            logger.error(f"Error in batch email processing: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def analyze_email_patterns(self, user_id: int, days_back: int = 30) -> Dict[str, Any]:
        """
        Analyze email communication patterns and generate insights.
        """
        try:
            from models.database import get_db_manager
            
            cutoff_date = datetime.utcnow() - timedelta(days=days_back)
            
            with get_db_manager().get_session() as session:
                emails = session.query(Email).filter(
                    Email.user_id == user_id,
                    Email.email_date > cutoff_date
                ).all()
                
                patterns = {
                    'total_emails': len(emails),
                    'communication_patterns': self._analyze_communication_patterns(emails),
                    'topic_trends': self._analyze_topic_trends(emails, user_id),
                    'relationship_activity': self._analyze_relationship_activity(emails, user_id),
                    'business_intelligence': self._generate_business_intelligence(emails, user_id),
                    'productivity_insights': self._generate_productivity_insights_from_emails(emails),
                    'strategic_recommendations': self._generate_strategic_recommendations(emails, user_id)
                }
                
                return {'success': True, 'result': patterns}
                
        except Exception as e:
            logger.error(f"Error analyzing email patterns: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    # =====================================================================
    # EMAIL INTELLIGENCE EXTRACTION
    # =====================================================================
    
    def extract_meeting_requests(self, email_data: Dict, user_id: int) -> Dict[str, Any]:
        """
        Extract meeting requests and create calendar preparation tasks.
        """
        try:
            # Check if email contains meeting-related content
            email_content = email_data.get('body_clean', '')
            subject = email_data.get('subject', '')
            
            meeting_indicators = [
                'meeting', 'call', 'discussion', 'catch up', 'sync',
                'available', 'schedule', 'calendar', 'time', 'when'
            ]
            
            has_meeting_content = any(indicator in email_content.lower() or 
                                    indicator in subject.lower() 
                                    for indicator in meeting_indicators)
            
            if not has_meeting_content:
                return {'success': True, 'result': {'has_meeting_request': False}}
            
            # Use AI to extract meeting details
            meeting_extraction_prompt = self._create_meeting_extraction_prompt(email_data)
            
            # This would call Claude to extract meeting details
            # For now, return a structured response
            meeting_info = {
                'has_meeting_request': True,
                'meeting_type': 'discussion',
                'suggested_participants': [email_data.get('sender')],
                'topic_hints': self._extract_topic_hints_from_content(email_content),
                'urgency_level': self._assess_meeting_urgency(email_content, subject),
                'preparation_tasks': self._generate_meeting_prep_tasks(email_data, user_id)
            }
            
            return {'success': True, 'result': meeting_info}
            
        except Exception as e:
            logger.error(f"Error extracting meeting requests: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def extract_business_context(self, email_data: Dict, user_id: int) -> Dict[str, Any]:
        """
        Extract business context and strategic intelligence from email.
        """
        try:
            # Get user context for enhanced analysis
            user_context = self.ai_processor._gather_user_context(user_id)
            
            context_analysis = {
                'business_category': self._categorize_business_content(email_data),
                'strategic_importance': self._assess_strategic_importance(email_data, user_context),
                'stakeholder_analysis': self._analyze_stakeholders(email_data, user_id),
                'project_connections': self._identify_project_connections(email_data, user_context),
                'decision_points': self._extract_decision_points(email_data),
                'follow_up_requirements': self._identify_follow_up_requirements(email_data),
                'competitive_intelligence': self._extract_competitive_intelligence(email_data),
                'opportunity_signals': self._detect_opportunity_signals(email_data, user_context)
            }
            
            return {'success': True, 'result': context_analysis}
            
        except Exception as e:
            logger.error(f"Error extracting business context: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def enhance_with_historical_context(self, email_data: Dict, user_id: int) -> Dict[str, Any]:
        """
        Enhance email analysis with historical communication context.
        """
        try:
            sender_email = email_data.get('sender', '')
            if not sender_email:
                return {'success': True, 'result': {'has_history': False}}
            
            # Get historical communication with this sender
            historical_context = self._get_sender_history(sender_email, user_id)
            
            if not historical_context:
                return {'success': True, 'result': {'has_history': False}}
            
            # Analyze communication patterns
            enhancement = {
                'has_history': True,
                'communication_frequency': historical_context['frequency'],
                'relationship_strength': historical_context['strength'],
                'common_topics': historical_context['topics'],
                'interaction_patterns': historical_context['patterns'],
                'relationship_trajectory': self._analyze_relationship_trajectory(historical_context),
                'contextual_insights': self._generate_contextual_insights(email_data, historical_context),
                'recommended_response_tone': self._recommend_response_tone(historical_context),
                'priority_adjustment': self._adjust_priority_with_history(email_data, historical_context)
            }
            
            return {'success': True, 'result': enhancement}
            
        except Exception as e:
            logger.error(f"Error enhancing with historical context: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    # =====================================================================
    # HELPER METHODS
    # =====================================================================
    
    def _normalize_email_data(self, email_data: Dict) -> Dict:
        """Normalize email data for consistent processing"""
        normalized = email_data.copy()
        
        # Ensure required fields exist
        required_fields = ['gmail_id', 'subject', 'sender', 'body_clean', 'email_date']
        for field in required_fields:
            if field not in normalized:
                normalized[field] = ''
        
        # Clean and normalize text fields
        if normalized.get('subject'):
            normalized['subject'] = self._clean_text(normalized['subject'])
        
        if normalized.get('body_clean'):
            normalized['body_clean'] = self._clean_text(normalized['body_clean'])
        
        # Normalize sender email
        if normalized.get('sender'):
            normalized['sender'] = normalized['sender'].lower().strip()
        
        return normalized
    
    def _is_duplicate_email(self, email_data: Dict, user_id: int) -> bool:
        """Check if email has already been processed with AI"""
        try:
            from models.database import get_db_manager
            
            gmail_id = email_data.get('gmail_id')
            if not gmail_id:
                return False
            
            with get_db_manager().get_session() as session:
                existing = session.query(Email).filter(
                    Email.user_id == user_id,
                    Email.gmail_id == gmail_id,
                    Email.ai_summary.isnot(None)  # Only consider it duplicate if AI-processed
                ).first()
                
                return existing is not None
                
        except Exception as e:
            logger.error(f"Error checking for duplicate email: {str(e)}")
            return False
    
    def _process_email_batch_chunk(self, email_batch: List[Dict], user_id: int, user_context: Dict) -> List[Dict]:
        """Process a chunk of emails in a batch"""
        results = []
        
        for email_data in email_batch:
            try:
                # Use cached context for efficiency
                result = self.ai_processor.process_email_with_context(
                    email_data, user_id, user_context
                )
                
                if result.success:
                    summary = {
                        'email_id': email_data.get('gmail_id'),
                        'processing_summary': {
                            'entities_created': result.entities_created,
                            'entities_updated': result.entities_updated,
                            'processing_time': result.processing_time,
                            'insights_generated': len(result.insights_generated)
                        }
                    }
                    results.append({'success': True, 'result': summary})
                else:
                    results.append({'success': False, 'error': result.error})
                    
            except Exception as e:
                results.append({'success': False, 'error': str(e)})
        
        return results
    
    def _create_intelligence_summary(self, result: Any, email_data: Dict) -> Dict:
        """Create intelligence summary from processing result"""
        return {
            'business_summary': 'Email processed with entity-centric intelligence',
            'key_entities': {
                'people_mentioned': result.entities_created.get('people', 0),
                'topics_discussed': result.entities_created.get('topics', 0),
                'tasks_extracted': result.entities_created.get('tasks', 0),
                'projects_referenced': result.entities_created.get('projects', 0)
            },
            'strategic_value': 'Medium',  # This would be calculated
            'follow_up_required': result.entities_created.get('tasks', 0) > 0
        }
    
    def _extract_entity_relationships(self, result: Any) -> List[Dict]:
        """Extract entity relationships from processing result"""
        # This would extract actual relationships
        # For now return placeholder
        return [
            {
                'relationship_type': 'person_discusses_topic',
                'entities': ['person:1', 'topic:2'],
                'strength': 0.8
            }
        ]
    
    def _extract_action_items(self, result: Any) -> List[Dict]:
        """Extract action items from processing result"""
        action_items = []
        
        # Tasks created are action items
        if result.entities_created.get('tasks', 0) > 0:
            action_items.append({
                'type': 'tasks_created',
                'count': result.entities_created['tasks'],
                'description': f"Created {result.entities_created['tasks']} tasks from email analysis"
            })
        
        # People to follow up with
        if result.entities_created.get('people', 0) > 0:
            action_items.append({
                'type': 'relationship_update',
                'count': result.entities_created['people'],
                'description': f"Updated {result.entities_created['people']} person profiles"
            })
        
        return action_items
    
    def _clean_text(self, text: str) -> str:
        """Clean and normalize text content"""
        if not text:
            return ''
        
        # Remove excessive whitespace
        text = re.sub(r'\s+', ' ', text)
        
        # Remove HTML entities
        text = re.sub(r'&[a-zA-Z0-9#]+;', '', text)
        
        return text.strip()
    
    # =====================================================================
    # ANALYSIS METHODS
    # =====================================================================
    
    def _analyze_communication_patterns(self, emails: List[Email]) -> Dict:
        """Analyze communication patterns from emails"""
        patterns = {
            'emails_per_day': len(emails) / 30,  # Assuming 30-day period
            'top_senders': self._get_top_senders(emails),
            'response_time_analysis': self._analyze_response_times(emails),
            'communication_times': self._analyze_communication_times(emails),
            'email_categories': self._categorize_emails(emails)
        }
        return patterns
    
    def _analyze_topic_trends(self, emails: List[Email], user_id: int) -> Dict:
        """Analyze topic trends from email communications"""
        try:
            from models.database import get_db_manager
            
            with get_db_manager().get_session() as session:
                # Get topics mentioned in recent emails
                topic_mentions = {}
                
                for email in emails:
                    if hasattr(email, 'primary_topic') and email.primary_topic:
                        topic_name = email.primary_topic.name
                        if topic_name not in topic_mentions:
                            topic_mentions[topic_name] = 0
                        topic_mentions[topic_name] += 1
                
                # Sort by frequency
                trending_topics = sorted(topic_mentions.items(), key=lambda x: x[1], reverse=True)
                
                return {
                    'trending_topics': trending_topics[:10],
                    'total_topics_discussed': len(topic_mentions),
                    'topic_distribution': topic_mentions
                }
                
        except Exception as e:
            logger.error(f"Error analyzing topic trends: {str(e)}")
            return {}
    
    def _analyze_relationship_activity(self, emails: List[Email], user_id: int) -> Dict:
        """Analyze relationship activity from emails"""
        sender_activity = {}
        
        for email in emails:
            sender = email.sender
            if sender not in sender_activity:
                sender_activity[sender] = {
                    'email_count': 0,
                    'last_contact': None,
                    'avg_importance': 0
                }
            
            sender_activity[sender]['email_count'] += 1
            sender_activity[sender]['last_contact'] = email.email_date
            
            if email.strategic_importance:
                current_avg = sender_activity[sender]['avg_importance']
                count = sender_activity[sender]['email_count']
                sender_activity[sender]['avg_importance'] = (
                    (current_avg * (count - 1) + email.strategic_importance) / count
                )
        
        # Sort by activity level
        active_relationships = sorted(
            sender_activity.items(), 
            key=lambda x: x[1]['email_count'], 
            reverse=True
        )
        
        return {
            'most_active_contacts': active_relationships[:10],
            'total_unique_contacts': len(sender_activity),
            'relationship_distribution': sender_activity
        }
    
    def _generate_business_intelligence(self, emails: List[Email], user_id: int) -> Dict:
        """Generate business intelligence from email patterns"""
        intelligence = {
            'communication_health': self._assess_communication_health(emails),
            'business_momentum': self._assess_business_momentum(emails),
            'opportunity_indicators': self._detect_opportunity_indicators(emails),
            'risk_signals': self._detect_risk_signals(emails),
            'strategic_priorities': self._identify_strategic_priorities(emails)
        }
        return intelligence
    
    def _generate_productivity_insights_from_emails(self, emails: List[Email]) -> List[str]:
        """Generate productivity insights from email analysis"""
        insights = []
        
        # Email volume analysis
        daily_average = len(emails) / 30
        if daily_average > 50:
            insights.append("High email volume detected. Consider email management strategies.")
        elif daily_average < 10:
            insights.append("Low email volume. Good email management or potential communication gaps.")
        
        # Response time analysis
        urgent_emails = [e for e in emails if e.urgency_score and e.urgency_score > 0.7]
        if urgent_emails:
            insights.append(f"{len(urgent_emails)} urgent emails detected. Prioritize timely responses.")
        
        return insights
    
    def _generate_strategic_recommendations(self, emails: List[Email], user_id: int) -> List[str]:
        """Generate strategic recommendations from email analysis"""
        recommendations = []
        
        # Analyze communication patterns for recommendations
        high_importance_emails = [e for e in emails if e.strategic_importance and e.strategic_importance > 0.7]
        
        if high_importance_emails:
            recommendations.append(
                f"Focus on {len(high_importance_emails)} high-importance communications for strategic impact."
            )
        
        # Analyze relationship building opportunities
        unique_senders = len(set(e.sender for e in emails))
        if unique_senders > 20:
            recommendations.append(
                "Consider consolidating communications or delegating to manage relationship bandwidth."
            )
        
        return recommendations
    
    # =====================================================================
    # UTILITY METHODS
    # =====================================================================
    
    def _get_top_senders(self, emails: List[Email]) -> List[Dict]:
        """Get top email senders by frequency"""
